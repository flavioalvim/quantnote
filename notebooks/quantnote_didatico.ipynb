{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QuantNote - Tutorial Did√°tico\n",
    "\n",
    "## Sistema Quantitativo para Probabilidades de Retorno Condicionadas por Regime\n",
    "\n",
    "Este notebook demonstra passo a passo o funcionamento do sistema QuantNote.\n",
    "\n",
    "### Objetivo\n",
    "Calcular a probabilidade de um ativo atingir um retorno alvo em H per√≠odos, condicionada ao regime de mercado atual.\n",
    "\n",
    "### Conceitos Principais\n",
    "1. **Log-Retornos**: Usamos log(P_t/P_{t-1}) pois s√£o aditivos e sim√©tricos\n",
    "2. **Slope (Inclina√ß√£o)**: Tend√™ncia calculada via regress√£o linear do log-pre√ßo\n",
    "3. **Volatilidade**: Desvio padr√£o dos retornos em janela m√≥vel\n",
    "4. **Regimes**: Estados do mercado (bull/bear/flat combinados com alta/baixa volatilidade)\n",
    "5. **K-Means**: Clustering para detectar regimes automaticamente\n",
    "6. **Walk-Forward**: Valida√ß√£o para evitar overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 1: Setup e Imports\n",
    "\n",
    "Primeiro, configuramos o ambiente e importamos os m√≥dulos necess√°rios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup do path para imports\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "\n",
    "# Imports padr√£o\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Verificar se os imports funcionam\n",
    "print(\"Python path configurado!\")\n",
    "print(f\"Diret√≥rio de trabalho: {os.getcwd()}\")\n",
    "\n",
    "# Configura√ß√£o de visualiza√ß√£o\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.width', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 2: Configura√ß√£o do Sistema\n",
    "\n",
    "O sistema usa Pydantic para validar configura√ß√µes. Isso garante que par√¢metros inv√°lidos sejam rejeitados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.settings import AnalysisConfig, InfrastructureConfig, Config\n",
    "\n",
    "# Criar configura√ß√£o\n",
    "config = Config()\n",
    "\n",
    "# Personalizar par√¢metros\n",
    "config.analysis.future_return_periods = 7  # Horizonte de 3 dias\n",
    "config.analysis.window_slope = 20          # Janela de 20 dias para slope\n",
    "config.analysis.window_volatility = 20     # Janela de 20 dias para volatilidade\n",
    "config.analysis.n_clusters = 6             # 3 regimes\n",
    "config.analysis.target_return = 0.05       # Target de 5%\n",
    "\n",
    "print(\"=== Configura√ß√£o de An√°lise ===\")\n",
    "print(f\"Horizonte futuro: {config.analysis.future_return_periods} dias\")\n",
    "print(f\"Janela slope: {config.analysis.window_slope}\")\n",
    "print(f\"Janela volatilidade: {config.analysis.window_volatility}\")\n",
    "print(f\"N√∫mero de clusters: {config.analysis.n_clusters}\")\n",
    "print(f\"Retorno alvo: {config.analysis.target_return:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 3: Obten√ß√£o de Dados\n",
    "\n",
    "Usamos `YahooDataSource` para baixar dados OHLCV. O sistema tem rate limiting para evitar bloqueio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.infrastructure.yahoo_data_source import YahooDataSource\n",
    "from src.infrastructure.parquet_repository import ParquetRepository\n",
    "from src.infrastructure.file_logger import FileLogger, NullLogger\n",
    "\n",
    "# Criar logger (usar NullLogger para menos output)\n",
    "logger = NullLogger()  # ou FileLogger(\"quantnote\") para logs detalhados\n",
    "\n",
    "# Data source e repository\n",
    "data_source = YahooDataSource(calls_per_minute=5, logger=logger)\n",
    "repository = ParquetRepository(data_dir=\"../data\", logger=logger)\n",
    "\n",
    "# Ticker a analisar\n",
    "ticker = \"BOVA11.SA\"  # ETF do Ibovespa\n",
    "\n",
    "print(f\"Buscando dados para {ticker}...\")\n",
    "\n",
    "# Tentar carregar do cache primeiro\n",
    "df = repository.load(ticker)\n",
    "if df is None:\n",
    "    print(\"Dados n√£o encontrados no cache. Baixando do Yahoo Finance...\")\n",
    "    df = data_source.fetch_ohlcv(ticker)\n",
    "    repository.save(df, ticker)\n",
    "    print(\"Dados salvos no cache.\")\n",
    "else:\n",
    "    print(\"Dados carregados do cache.\")\n",
    "\n",
    "print(f\"\\n=== Dados Obtidos ===\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Per√≠odo: {df['date'].min().date()} a {df['date'].max().date()}\")\n",
    "print(f\"\\nPrimeiras linhas:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 4: Valida√ß√£o de Dados\n",
    "\n",
    "Antes de processar, validamos os dados para garantir qualidade.\n",
    "\n",
    "O sistema usa o padr√£o **Composite** para combinar m√∫ltiplos validadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.infrastructure.validators import create_default_validator\n",
    "\n",
    "# Criar validador composto\n",
    "validator = create_default_validator(\n",
    "    min_length=config.analysis.min_data_points,\n",
    "    max_window=max(config.analysis.window_slope, config.analysis.window_volatility)\n",
    ")\n",
    "\n",
    "# Executar valida√ß√£o\n",
    "validation = validator.validate(df)\n",
    "\n",
    "print(\"=== Resultado da Valida√ß√£o ===\")\n",
    "print(f\"V√°lido: {'SIM' if validation.is_valid else 'N√ÉO'}\")\n",
    "\n",
    "if validation.errors:\n",
    "    print(f\"\\nERROS:\")\n",
    "    for error in validation.errors:\n",
    "        print(f\"  - {error}\")\n",
    "\n",
    "if validation.warnings:\n",
    "    print(f\"\\nAVISOS:\")\n",
    "    for warning in validation.warnings:\n",
    "        print(f\"  - {warning}\")\n",
    "\n",
    "if validation.is_valid and not validation.warnings:\n",
    "    print(\"Todos os testes passaram sem avisos!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 5: Calculadores Individuais\n",
    "\n",
    "Vamos explorar cada calculador individualmente para entender o que faz.\n",
    "\n",
    "Cada calculador implementa `IColumnCalculator` e segue o princ√≠pio de **Single Responsibility**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.calculators.log_price_calculator import LogPriceCalculator\n",
    "\n",
    "# 5.1 - Log Price Calculator\n",
    "log_price_calc = LogPriceCalculator()\n",
    "\n",
    "print(\"=== LogPriceCalculator ===\")\n",
    "print(f\"Nome: {log_price_calc.name}\")\n",
    "print(f\"Colunas requeridas: {log_price_calc.required_columns}\")\n",
    "print(f\"Colunas produzidas: {log_price_calc.output_columns}\")\n",
    "\n",
    "# Aplicar\n",
    "df_step1 = log_price_calc.calculate(df)\n",
    "\n",
    "# Visualizar resultado\n",
    "print(f\"\\nFormula: log_close = ln(close)\")\n",
    "print(f\"\\nExemplo:\")\n",
    "print(df_step1[['date', 'close', 'log_close']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.calculators.log_return_calculator import LogReturnCalculator\n",
    "\n",
    "# 5.2 - Log Return Calculator\n",
    "log_return_calc = LogReturnCalculator(window=config.analysis.window_rolling_return)\n",
    "\n",
    "print(\"=== LogReturnCalculator ===\")\n",
    "print(f\"Nome: {log_return_calc.name}\")\n",
    "print(f\"Colunas requeridas: {log_return_calc.required_columns}\")\n",
    "print(f\"Colunas produzidas: {log_return_calc.output_columns}\")\n",
    "\n",
    "# Aplicar\n",
    "df_step2 = log_return_calc.calculate(df_step1)\n",
    "\n",
    "print(f\"\\nFormulas:\")\n",
    "print(f\"  log_return = ln(close_t / close_{{t-1}})\")\n",
    "print(f\"  log_return_rolling_20 = sum(log_return over 20 days)\")\n",
    "print(f\"\\nExemplo:\")\n",
    "print(df_step2[['date', 'close', 'log_return', f'log_return_rolling_{config.analysis.window_rolling_return}']].head(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.calculators.volatility_calculator import VolatilityCalculator\n",
    "\n",
    "# 5.3 - Volatility Calculator\n",
    "vol_calc = VolatilityCalculator(window=config.analysis.window_volatility)\n",
    "\n",
    "print(\"=== VolatilityCalculator ===\")\n",
    "print(f\"Nome: {vol_calc.name}\")\n",
    "print(f\"Colunas requeridas: {vol_calc.required_columns}\")\n",
    "print(f\"Colunas produzidas: {vol_calc.output_columns}\")\n",
    "\n",
    "# Aplicar\n",
    "df_step3 = vol_calc.calculate(df_step2)\n",
    "\n",
    "print(f\"\\nFormula: volatility = std(log_return over {config.analysis.window_volatility} days)\")\n",
    "print(f\"\\nExemplo:\")\n",
    "print(df_step3[['date', 'log_return', f'volatility_{config.analysis.window_volatility}']].tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.calculators.slope_calculator import SlopeCalculator\n",
    "\n",
    "# 5.4 - Slope Calculator\n",
    "slope_calc = SlopeCalculator(window=config.analysis.window_slope)\n",
    "\n",
    "print(\"=== SlopeCalculator ===\")\n",
    "print(f\"Nome: {slope_calc.name}\")\n",
    "print(f\"Colunas requeridas: {slope_calc.required_columns}\")\n",
    "print(f\"Colunas produzidas: {slope_calc.output_columns}\")\n",
    "\n",
    "# Aplicar\n",
    "df_step4 = slope_calc.calculate(df_step3)\n",
    "\n",
    "print(f\"\\nFormula: slope = coef angular da regress√£o linear de log_close sobre {config.analysis.window_slope} dias\")\n",
    "print(f\"\\nInterpreta√ß√£o:\")\n",
    "print(f\"  slope > 0: tend√™ncia de alta\")\n",
    "print(f\"  slope < 0: tend√™ncia de baixa\")\n",
    "print(f\"  slope ‚âà 0: mercado lateral\")\n",
    "print(f\"\\nExemplo:\")\n",
    "print(df_step4[['date', 'log_close', f'slope_{config.analysis.window_slope}']].tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.calculators.future_return_calculator import FutureReturnCalculator\n",
    "\n",
    "# 5.5 - Future Return Calculator\n",
    "future_calc = FutureReturnCalculator(horizon=config.analysis.future_return_periods)\n",
    "\n",
    "print(\"=== FutureReturnCalculator ===\")\n",
    "print(f\"Nome: {future_calc.name}\")\n",
    "print(f\"Colunas requeridas: {future_calc.required_columns}\")\n",
    "print(f\"Colunas produzidas: {future_calc.output_columns}\")\n",
    "\n",
    "# Aplicar\n",
    "df_step5 = future_calc.calculate(df_step4)\n",
    "\n",
    "print(f\"\\nFormula: log_return_future_{config.analysis.future_return_periods} = ln(close_{{t+{config.analysis.future_return_periods}}} / close_t)\")\n",
    "print(f\"\\nNOTA: Esta coluna √© a vari√°vel TARGET que queremos prever!\")\n",
    "print(f\"\\nExemplo:\")\n",
    "print(df_step5[['date', 'close', f'log_return_future_{config.analysis.future_return_periods}']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 6: Pipeline com Resolu√ß√£o Autom√°tica de Depend√™ncias\n",
    "\n",
    "O `CalculatorPipeline` usa **topological sort** para ordenar os calculadores automaticamente.\n",
    "\n",
    "Isso implementa o princ√≠pio **Open/Closed** - podemos adicionar calculadores sem modificar o pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.calculators.pipeline import CalculatorPipeline\n",
    "from src.calculators.log_price_calculator import LogPriceCalculator\n",
    "from src.calculators.log_return_calculator import LogReturnCalculator\n",
    "from src.calculators.future_return_calculator import FutureReturnCalculator\n",
    "from src.calculators.volatility_calculator import VolatilityCalculator\n",
    "from src.calculators.slope_calculator import SlopeCalculator\n",
    "\n",
    "# Criar pipeline (note que a ordem n√£o importa - ser√° resolvida automaticamente)\n",
    "pipeline = CalculatorPipeline([\n",
    "    SlopeCalculator(window=config.analysis.window_slope),      # Depende de log_close\n",
    "    LogReturnCalculator(window=config.analysis.window_rolling_return),  # Depende de close\n",
    "    VolatilityCalculator(window=config.analysis.window_volatility),     # Depende de log_return\n",
    "    LogPriceCalculator(),                                       # Depende de close\n",
    "    FutureReturnCalculator(horizon=config.analysis.future_return_periods)  # Depende de close\n",
    "], logger=logger)\n",
    "\n",
    "# Executar pipeline\n",
    "df_analysis = pipeline.run(df)\n",
    "\n",
    "print(\"=== Pipeline Executado ===\")\n",
    "print(f\"Ordem de execu√ß√£o: {pipeline.get_execution_order()}\")\n",
    "print(f\"\\nColunas originais: {len(df.columns)}\")\n",
    "print(f\"Colunas ap√≥s pipeline: {len(df_analysis.columns)}\")\n",
    "print(f\"\\nNovas colunas: {list(pipeline.get_all_output_columns())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar resultado do pipeline\n",
    "print(\"=== Dados Ap√≥s Pipeline ===\")\n",
    "df_analysis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 7: Classifica√ß√£o Manual de Regimes\n",
    "\n",
    "Uma abordagem √© usar thresholds manuais para classificar regimes baseado em slope e volatilidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analysis.regime_classifier import ManualRegimeClassifier\n",
    "\n",
    "# Nomes das colunas\n",
    "slope_col = f'slope_{config.analysis.window_slope}'\n",
    "vol_col = f'volatility_{config.analysis.window_volatility}'\n",
    "\n",
    "# Criar classificador manual (thresholds autom√°ticos)\n",
    "manual_classifier = ManualRegimeClassifier(\n",
    "    slope_column=slope_col,\n",
    "    volatility_column=vol_col\n",
    ")\n",
    "\n",
    "# Classificar\n",
    "df_manual = manual_classifier.classify(df_analysis)\n",
    "\n",
    "# Resultados\n",
    "print(\"=== Classifica√ß√£o Manual de Regimes ===\")\n",
    "print(f\"\\nThresholds usados: {manual_classifier.get_thresholds()}\")\n",
    "print(f\"\\nDistribui√ß√£o de regimes:\")\n",
    "print(df_manual['regime'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar distribui√ß√£o por regime\n",
    "regime_counts = df_manual['regime'].value_counts()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "colors = {\n",
    "    'bull_high_vol': 'lightgreen',\n",
    "    'bull_low_vol': 'darkgreen',\n",
    "    'bear_high_vol': 'lightcoral',\n",
    "    'bear_low_vol': 'darkred',\n",
    "    'flat_high_vol': 'yellow',\n",
    "    'flat_low_vol': 'gold'\n",
    "}\n",
    "bar_colors = [colors.get(r, 'gray') for r in regime_counts.index]\n",
    "regime_counts.plot(kind='bar', ax=ax, color=bar_colors, edgecolor='black')\n",
    "ax.set_title('Distribui√ß√£o de Regimes (Classifica√ß√£o Manual)')\n",
    "ax.set_xlabel('Regime')\n",
    "ax.set_ylabel('Frequ√™ncia')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 8: Classifica√ß√£o com K-Means\n",
    "\n",
    "K-Means detecta regimes automaticamente baseado em m√∫ltiplas features.\n",
    "\n",
    "Isso √© mais robusto que thresholds manuais pois considera todas as features simultaneamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analysis.kmeans_regimes import KMeansRegimeClassifier\n",
    "\n",
    "# Criar classificador K-Means\n",
    "kmeans = KMeansRegimeClassifier(\n",
    "    n_clusters=config.analysis.n_clusters,\n",
    "    logger=logger\n",
    ")\n",
    "\n",
    "# Fit e Predict\n",
    "df_kmeans = kmeans.fit_predict(df_analysis)\n",
    "\n",
    "print(\"=== Classifica√ß√£o K-Means ===\")\n",
    "print(f\"\\nFeatures usadas: {kmeans.feature_columns}\")\n",
    "print(f\"N√∫mero de clusters: {config.analysis.n_clusters}\")\n",
    "print(f\"\\nDistribui√ß√£o de clusters:\")\n",
    "print(df_kmeans['cluster'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estat√≠sticas por cluster\n",
    "future_col = f'log_return_future_{config.analysis.future_return_periods}'\n",
    "stats = kmeans.compute_statistics(df_kmeans, future_col)\n",
    "interpretations = kmeans.interpret_clusters(df_kmeans, slope_col)\n",
    "\n",
    "print(\"=== Estat√≠sticas por Cluster ===\")\n",
    "for stat in stats:\n",
    "    interp = interpretations.get(stat.cluster_id, 'unknown')\n",
    "    print(f\"\\nCluster {stat.cluster_id} ({interp.upper()}):\")\n",
    "    print(f\"  Observa√ß√µes: {stat.count} ({stat.percentage:.1f}%)\")\n",
    "    print(f\"  Retorno futuro m√©dio: {stat.future_return_mean:.4f}\")\n",
    "    print(f\"  Desvio padr√£o: {stat.future_return_std:.4f}\")\n",
    "    print(f\"  Features m√©dias: {stat.feature_means}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 9: C√°lculo de Probabilidades\n",
    "\n",
    "Agora calculamos a probabilidade de atingir o retorno alvo, condicionada por regime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analysis.probability_calculator import ProbabilityCalculator\n",
    "\n",
    "# Usando classifica√ß√£o manual\n",
    "prob_calc_manual = ProbabilityCalculator(\n",
    "    future_return_column=future_col,\n",
    "    target_return=config.analysis.target_return,\n",
    "    regime_column='regime'\n",
    ")\n",
    "\n",
    "# Gerar relat√≥rio completo\n",
    "report = prob_calc_manual.generate_report(df_manual)\n",
    "\n",
    "print(\"=== Relat√≥rio de Probabilidades (Regimes Manuais) ===\")\n",
    "print(f\"\\nRetorno alvo: {report['target_return']:.1%}\")\n",
    "print(f\"Log-retorno alvo: {report['log_target']:.4f}\")\n",
    "print(f\"\\nProbabilidade incondicional: {report['raw_probability_pct']:.2f}%\")\n",
    "\n",
    "print(f\"\\nProbabilidades condicionais:\")\n",
    "for regime, data in report['conditional_probabilities'].items():\n",
    "    print(f\"  {regime}:\")\n",
    "    print(f\"    P(hit) = {data['probability_pct']:.2f}%\")\n",
    "    print(f\"    n = {data['count']}\")\n",
    "    print(f\"    retorno m√©dio = {data['mean_return']:.4f}\")\n",
    "\n",
    "print(f\"\\nM√©tricas de separa√ß√£o:\")\n",
    "print(f\"  Delta P: {report['separation_metrics']['delta_p']:.4f}\")\n",
    "print(f\"  (diferen√ßa entre maior e menor probabilidade)\")\n",
    "print(f\"  Information Ratio: {report['separation_metrics']['information_ratio']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando classifica√ß√£o K-Means\n",
    "prob_calc_kmeans = ProbabilityCalculator(\n",
    "    future_return_column=future_col,\n",
    "    target_return=config.analysis.target_return,\n",
    "    regime_column='cluster'\n",
    ")\n",
    "\n",
    "report_kmeans = prob_calc_kmeans.generate_report(df_kmeans)\n",
    "\n",
    "print(\"=== Relat√≥rio de Probabilidades (K-Means) ===\")\n",
    "print(f\"\\nRetorno alvo: {report_kmeans['target_return']:.1%}\")\n",
    "print(f\"\\nProbabilidade incondicional: {report_kmeans['raw_probability_pct']:.2f}%\")\n",
    "\n",
    "print(f\"\\nProbabilidades por cluster:\")\n",
    "for cluster_id, data in sorted(report_kmeans['conditional_probabilities'].items()):\n",
    "    interp = interpretations.get(int(float(cluster_id)), 'unknown')\n",
    "    print(f\"  Cluster {cluster_id} ({interp}): P(hit) = {data['probability_pct']:.2f}% (n={data['count']})\")\n",
    "\n",
    "print(f\"\\nDelta P: {report_kmeans['separation_metrics']['delta_p']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 10: Visualiza√ß√µes\n",
    "\n",
    "Visualizamos a distribui√ß√£o de retornos por regime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.visualization.histogram_plotter import HistogramPlotter, PriceRegimePlotter\n",
    "\n",
    "# Histograma geral\n",
    "hist_plotter = HistogramPlotter(\n",
    "    return_column=future_col,\n",
    "    regime_column='regime'\n",
    ")\n",
    "\n",
    "fig = hist_plotter.plot(df_manual)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramas por regime\n",
    "fig = hist_plotter.plot_by_regime(df_manual, target_return=config.analysis.target_return)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre√ßo com background de regime\n",
    "df_manual_indexed = df_manual.set_index('date')\n",
    "\n",
    "price_plotter = PriceRegimePlotter(regime_column='regime')\n",
    "fig = price_plotter.plot(df_manual_indexed)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 11: Walk-Forward Validation\n",
    "\n",
    "Para evitar overfitting, usamos walk-forward validation.\n",
    "\n",
    "Isso simula como o modelo performaria em tempo real, sempre treinando no passado e testando no futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analysis.time_series_splitter import TimeSeriesSplitter\n",
    "\n",
    "# Criar splitter\n",
    "splitter = TimeSeriesSplitter(train_ratio=0.7)\n",
    "\n",
    "# Demonstrar walk-forward splits\n",
    "print(\"=== Walk-Forward Splits ===\")\n",
    "for split in splitter.walk_forward_split(df, n_folds=5, min_train_size=252):\n",
    "    train_start = split.train['date'].min().date()\n",
    "    train_end = split.train['date'].max().date()\n",
    "    test_start = split.test['date'].min().date()\n",
    "    test_end = split.test['date'].max().date()\n",
    "    \n",
    "    print(f\"\\nFold {split.fold}:\")\n",
    "    print(f\"  Train: {train_start} a {train_end} ({len(split.train)} obs)\")\n",
    "    print(f\"  Test:  {test_start} a {test_end} ({len(split.test)} obs)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 12: Otimiza√ß√£o com Algoritmo Gen√©tico (Otimizado)\n",
    "\n",
    "O GA busca os melhores par√¢metros automaticamente.\n",
    "\n",
    "**Otimiza√ß√µes implementadas:**\n",
    "1. **Paraleliza√ß√£o**: Avalia√ß√£o de fitness usa m√∫ltiplos cores CPU\n",
    "2. **Cache**: Cromossomos id√™nticos n√£o s√£o reavaliados\n",
    "3. **Numba**: C√°lculo de slope ~10-50x mais r√°pido (ap√≥s warm-up)\n",
    "4. **KMeans otimizado**: Algoritmo Lloyd para melhor performance\n",
    "\n",
    "**NOTA sobre Numba**: A primeira execu√ß√£o ser√° mais lenta devido √† compila√ß√£o JIT. Execu√ß√µes subsequentes ser√£o significativamente mais r√°pidas. O cache do Numba persiste entre sess√µes.\n",
    "\n",
    "**NOTA**: Esta etapa √© computacionalmente intensiva. Reduzimos os par√¢metros para demonstra√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.search_space import GAConfig, GASearchSpace\n",
    "from src.optimization.genetic_algorithm import GeneticAlgorithm\n",
    "from src.calculators.slope_calculator import SlopeCalculator\n",
    "import multiprocessing as mp\n",
    "\n",
    "# Verificar otimiza√ß√µes dispon√≠veis\n",
    "print(\"=== Verifica√ß√£o de Otimiza√ß√µes ===\")\n",
    "print(f\"Numba dispon√≠vel para SlopeCalculator: {SlopeCalculator.is_numba_available()}\")\n",
    "print(f\"CPUs dispon√≠veis para paraleliza√ß√£o: {mp.cpu_count()}\")\n",
    "\n",
    "# Configura√ß√£o do GA\n",
    "# target_return e horizon s√£o FIXOS - o GA otimiza apenas os par√¢metros de feature engineering\n",
    "ga_config = GAConfig(\n",
    "    # Par√¢metros de predi√ß√£o (fixos)\n",
    "    target_return=0.01,   # Queremos prever varia√ß√£o de 1%\n",
    "    horizon=2,            # Em 2 dias\n",
    "    \n",
    "    # Par√¢metros do GA\n",
    "    population_size=500,\n",
    "    generations=10000,\n",
    "    n_folds=3,\n",
    "    stability_penalty=0.1,\n",
    "    elite_size=2,\n",
    "    \n",
    "    # Early stopping\n",
    "    early_stopping=False,  # Desabilitado para rodar todas as gera√ß√µes\n",
    ")\n",
    "\n",
    "print(\"\\n=== Configura√ß√£o do GA ===\")\n",
    "print(f\"Target Return: {ga_config.target_return:.1%}\")\n",
    "print(f\"Horizonte: {ga_config.horizon} dias\")\n",
    "print(f\"Popula√ß√£o: {ga_config.population_size}\")\n",
    "print(f\"Gera√ß√µes: {ga_config.generations}\")\n",
    "print(f\"Folds: {ga_config.n_folds}\")\n",
    "print(f\"Early Stopping: {ga_config.early_stopping}\")\n",
    "\n",
    "# Estimativa de tempo\n",
    "tempo_por_gen = ga_config.population_size * 0.035  # ~0.035s por cromossomo\n",
    "tempo_total = ga_config.generations * tempo_por_gen\n",
    "print(f\"\\nTempo estimado: {tempo_total/60:.1f} minutos\")\n",
    "print(\"\\nNOTA: Use Ctrl+C para interromper e salvar checkpoint a qualquer momento.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.optimization.genetic_algorithm import GeneticAlgorithm, GACheckpoint\n",
    "from src.optimization.progress_callback import LiveProgressCallback\n",
    "\n",
    "# Criar callback de progresso visual\n",
    "progress_callback = LiveProgressCallback(\n",
    "    total_generations=ga_config.generations,\n",
    "    population_size=ga_config.population_size,\n",
    "    update_every=1\n",
    ")\n",
    "\n",
    "# Executar GA\n",
    "# NOTA: parallel=False √© mais est√°vel em Jupyter notebooks\n",
    "ga = GeneticAlgorithm(\n",
    "    df, \n",
    "    ga_config, \n",
    "    logger=logger,\n",
    "    progress_callback=progress_callback,\n",
    "    n_workers=None\n",
    ")\n",
    "\n",
    "try:\n",
    "    result = ga.run(\n",
    "        verbose=False,\n",
    "        parallel=False,  # Desativado para evitar problemas no Jupyter\n",
    "        auto_checkpoint_path=\"ga_checkpoint.json\",\n",
    "        checkpoint_every=10\n",
    "    )\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nInterrompido! Salvando checkpoint...\")\n",
    "    ga.save_checkpoint(\"ga_checkpoint.json\")\n",
    "    print(\"Checkpoint salvo em 'ga_checkpoint.json'\")\n",
    "    print(\"Para retomar: checkpoint = GACheckpoint.load('ga_checkpoint.json')\")\n",
    "    raise\n",
    "\n",
    "progress_callback.finalize()\n",
    "\n",
    "print(\"\\n=== Melhores Par√¢metros Encontrados ===\")\n",
    "best = result.best_chromosome\n",
    "print(f\"  Window Slope: {best.window_slope}\")\n",
    "print(f\"  Window Volatility: {best.window_volatility}\")\n",
    "print(f\"  Window Rolling Return: {best.window_rolling_return}\")\n",
    "print(f\"  N Clusters: {best.n_clusters}\")\n",
    "print(f\"  Use Volatility: {best.use_volatility}\")\n",
    "print(f\"  Use Rolling Return: {best.use_rolling_return}\")\n",
    "\n",
    "print(f\"\\nPar√¢metros fixos (da configura√ß√£o):\")\n",
    "print(f\"  Target Return: {ga_config.target_return:.2%}\")\n",
    "print(f\"  Horizon: {ga_config.horizon} dias\")\n",
    "\n",
    "print(f\"\\nM√©tricas:\")\n",
    "print(f\"  Fitness: {result.best_fitness:.4f}\")\n",
    "print(f\"  Delta P (test): {result.best_metrics.delta_p_test:.4f}\")\n",
    "print(f\"  Overfitting Ratio: {result.best_metrics.overfitting_ratio:.2f}\")\n",
    "\n",
    "print(f\"\\nEstat√≠sticas:\")\n",
    "print(f\"  Total avalia√ß√µes: {result.all_evaluations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar evolu√ß√£o do fitness\n",
    "generations = [h[0] for h in result.history]\n",
    "best_fitness = [h[1] for h in result.history]\n",
    "mean_fitness = [h[2] for h in result.history]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(generations, best_fitness, 'b-', label='Best Fitness', linewidth=2)\n",
    "ax.plot(generations, mean_fitness, 'g--', label='Mean Fitness', alpha=0.7)\n",
    "ax.set_xlabel('Generation')\n",
    "ax.set_ylabel('Fitness')\n",
    "ax.set_title('Evolu√ß√£o do Algoritmo Gen√©tico')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 13: Aplicar Melhores Par√¢metros\n",
    "\n",
    "Agora aplicamos os par√¢metros otimizados e recalculamos as probabilidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.optimization.calculator_factory import CalculatorFactory\n",
    "\n",
    "# Factory para criar pipeline com os melhores par√¢metros\n",
    "# horizon vem da configura√ß√£o, n√£o do cromossomo\n",
    "factory = CalculatorFactory(horizon=ga_config.horizon)\n",
    "best_pipeline = factory.create_pipeline(best)\n",
    "feature_cols = factory.get_feature_columns(best)\n",
    "future_col_best = factory.get_future_return_column()\n",
    "\n",
    "# Processar dados\n",
    "df_best = best_pipeline.run(df)\n",
    "\n",
    "# Clustering\n",
    "best_kmeans = KMeansRegimeClassifier(\n",
    "    n_clusters=best.n_clusters,\n",
    "    feature_columns=feature_cols\n",
    ")\n",
    "df_best = best_kmeans.fit_predict(df_best)\n",
    "\n",
    "# Probabilidades (target_return vem da configura√ß√£o)\n",
    "best_prob = ProbabilityCalculator(\n",
    "    future_return_column=future_col_best,\n",
    "    target_return=ga_config.target_return,\n",
    "    regime_column='cluster'\n",
    ")\n",
    "\n",
    "best_report = best_prob.generate_report(df_best)\n",
    "\n",
    "print(\"=== Relat√≥rio com Par√¢metros Otimizados ===\")\n",
    "print(f\"\\nRetorno alvo: {ga_config.target_return:.1%}\")\n",
    "print(f\"Horizonte: {ga_config.horizon} dias\")\n",
    "print(f\"\\nProbabilidade incondicional: {best_report['raw_probability_pct']:.2f}%\")\n",
    "\n",
    "# Interpretar clusters\n",
    "slope_col_best = f'slope_{best.window_slope}'\n",
    "best_interp = best_kmeans.interpret_clusters(df_best, slope_col_best)\n",
    "\n",
    "print(f\"\\nProbabilidades por cluster:\")\n",
    "for cluster_id, data in sorted(best_report['conditional_probabilities'].items()):\n",
    "    interp = best_interp.get(int(float(cluster_id)), 'unknown')\n",
    "    print(f\"  Cluster {cluster_id} ({interp.upper()}): P(hit) = {data['probability_pct']:.2f}% (n={data['count']})\")\n",
    "\n",
    "print(f\"\\nDelta P: {best_report['separation_metrics']['delta_p']:.4f}\")\n",
    "print(f\"Information Ratio: {best_report['separation_metrics']['information_ratio']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 14: Visualiza√ß√µes com Par√¢metros Otimizados\n",
    "\n",
    "Agora repetimos todas as visualiza√ß√µes usando os par√¢metros do indiv√≠duo vencedor do GA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estat√≠sticas por cluster com par√¢metros otimizados\n",
    "stats_best = best_kmeans.compute_statistics(df_best, future_col_best)\n",
    "\n",
    "print(\"=== Estat√≠sticas por Cluster (Par√¢metros Otimizados) ===\")\n",
    "for stat in stats_best:\n",
    "    interp = best_interp.get(stat.cluster_id, 'unknown')\n",
    "    print(f\"\\nCluster {stat.cluster_id} ({interp.upper()}):\")\n",
    "    print(f\"  Observa√ß√µes: {stat.count} ({stat.percentage:.1f}%)\")\n",
    "    print(f\"  Retorno futuro m√©dio: {stat.future_return_mean:.4f}\")\n",
    "    print(f\"  Desvio padr√£o: {stat.future_return_std:.4f}\")\n",
    "    print(f\"  Features m√©dias: {stat.feature_means}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograma de retornos com par√¢metros otimizados\n",
    "hist_plotter_best = HistogramPlotter(\n",
    "    return_column=future_col_best,\n",
    "    regime_column='cluster'\n",
    ")\n",
    "\n",
    "fig = hist_plotter_best.plot(df_best)\n",
    "plt.suptitle(f'Distribui√ß√£o de Retornos Futuros ({ga_config.horizon} dias) - Par√¢metros Otimizados', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramas por cluster com linha do target\n",
    "fig = hist_plotter_best.plot_by_regime(df_best, target_return=ga_config.target_return)\n",
    "plt.suptitle(f'Distribui√ß√£o por Cluster - Target: {ga_config.target_return:.1%} em {ga_config.horizon} dias', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre√ßo com background de cluster otimizado\n",
    "df_best_indexed = df_best.set_index('date')\n",
    "\n",
    "price_plotter_best = PriceRegimePlotter(regime_column='cluster')\n",
    "fig = price_plotter_best.plot(df_best_indexed)\n",
    "plt.suptitle('Pre√ßo com Regimes Otimizados pelo GA', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°fico de barras: Probabilidade por Cluster\n",
    "clusters = []\n",
    "probs = []\n",
    "colors = []\n",
    "color_map = {'bull': 'green', 'bear': 'red', 'flat': 'gold'}\n",
    "\n",
    "for cluster_id, data in sorted(best_report['conditional_probabilities'].items()):\n",
    "    interp = best_interp.get(int(float(cluster_id)), 'flat')\n",
    "    clusters.append(f\"Cluster {int(float(cluster_id))}\\n({interp})\")\n",
    "    probs.append(data['probability_pct'])\n",
    "    colors.append(color_map.get(interp, 'gray'))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "bars = ax.bar(clusters, probs, color=colors, edgecolor='black', alpha=0.8)\n",
    "\n",
    "# Linha horizontal para probabilidade incondicional\n",
    "ax.axhline(y=best_report['raw_probability_pct'], color='blue', linestyle='--', \n",
    "           linewidth=2, label=f\"P incondicional: {best_report['raw_probability_pct']:.1f}%\")\n",
    "\n",
    "# Adicionar valores nas barras\n",
    "for bar, prob in zip(bars, probs):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
    "            f'{prob:.1f}%', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "ax.set_ylabel('Probabilidade (%)')\n",
    "ax.set_title(f'Probabilidade de Atingir {ga_config.target_return:.1%} em {ga_config.horizon} dias por Cluster')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nDelta P (separa√ß√£o): {best_report['separation_metrics']['delta_p']:.4f}\")\n",
    "print(f\"Melhor cluster: {max(best_report['conditional_probabilities'].items(), key=lambda x: x[1]['probability_pct'])[0]}\")\n",
    "print(f\"Pior cluster: {min(best_report['conditional_probabilities'].items(), key=lambda x: x[1]['probability_pct'])[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar regime atual e probabilidade\n",
    "last_row = df_best.iloc[-1]\n",
    "current_cluster = int(last_row['cluster'])\n",
    "current_interp = best_interp.get(current_cluster, 'unknown')\n",
    "current_prob = best_report['conditional_probabilities'][str(float(current_cluster))]['probability_pct']\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SITUA√á√ÉO ATUAL\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nData mais recente: {last_row['date'].strftime('%Y-%m-%d')}\")\n",
    "print(f\"Pre√ßo de fechamento: R$ {last_row['close']:.2f}\")\n",
    "print(f\"\\nRegime atual: Cluster {current_cluster} ({current_interp.upper()})\")\n",
    "print(f\"\\nProbabilidade de atingir {ga_config.target_return:.1%} em {ga_config.horizon} dias:\")\n",
    "print(f\"  -> {current_prob:.1f}%\")\n",
    "print(f\"\\nProbabilidade incondicional (m√©dia hist√≥rica): {best_report['raw_probability_pct']:.1f}%\")\n",
    "\n",
    "# Compara√ß√£o\n",
    "diff = current_prob - best_report['raw_probability_pct']\n",
    "if diff > 0:\n",
    "    print(f\"\\n‚úÖ Regime atual tem probabilidade {diff:.1f} pontos percentuais ACIMA da m√©dia\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Regime atual tem probabilidade {abs(diff):.1f} pontos percentuais ABAIXO da m√©dia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<cell_type>markdown</cell_type>## Etapa 15: An√°lise Dual - Fechar vs Tocar\n",
    "\n",
    "Comparamos duas probabilidades diferentes:\n",
    "- **P(fechar)**: Probabilidade do pre√ßo FECHAR acima do alvo em t+H\n",
    "- **P(tocar)**: Probabilidade do pre√ßo TOCAR o alvo em algum momento entre t+1 e t+H\n",
    "\n",
    "Esta an√°lise √© √∫til para opera√ß√µes de op√ß√µes e stop-loss/take-profit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.calculators import FutureTouchCalculatorVectorized\n",
    "from src.analysis import DualProbabilityCalculator\n",
    "\n",
    "# Adicionar colunas de touch ao DataFrame com par√¢metros otimizados\n",
    "touch_calc = FutureTouchCalculatorVectorized(horizon=ga_config.horizon)\n",
    "df_dual = touch_calc.calculate(df_best)\n",
    "\n",
    "print(\"=== Novas Colunas de Touch ===\")\n",
    "print(f\"Colunas adicionadas: {touch_calc.output_columns}\")\n",
    "print(f\"\\nExemplo dos dados:\")\n",
    "print(df_dual[['date', 'close', f'log_return_future_{ga_config.horizon}', \n",
    "               f'log_return_touch_max_{ga_config.horizon}']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar calculador dual\n",
    "dual_calc = DualProbabilityCalculator(\n",
    "    close_return_column=f'log_return_future_{ga_config.horizon}',\n",
    "    touch_return_column=f'log_return_touch_max_{ga_config.horizon}',  # Para alvos de alta\n",
    "    target_return=ga_config.target_return,\n",
    "    regime_column='cluster'\n",
    ")\n",
    "\n",
    "# Imprimir compara√ß√£o formatada\n",
    "dual_calc.print_comparison(df_dual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°fico comparativo: P(fechar) vs P(tocar) por cluster\n",
    "dual_report = dual_calc.generate_report(df_dual)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "clusters_list = sorted(dual_report['conditional_probabilities'].keys())\n",
    "x = np.arange(len(clusters_list))\n",
    "width = 0.35\n",
    "\n",
    "close_probs = [dual_report['conditional_probabilities'][c]['prob_close'] * 100 for c in clusters_list]\n",
    "touch_probs = [dual_report['conditional_probabilities'][c]['prob_touch'] * 100 for c in clusters_list]\n",
    "\n",
    "bars1 = ax.bar(x - width/2, close_probs, width, label='P(fechar)', color='steelblue', alpha=0.8)\n",
    "bars2 = ax.bar(x + width/2, touch_probs, width, label='P(tocar)', color='coral', alpha=0.8)\n",
    "\n",
    "# Labels nos clusters\n",
    "cluster_labels = []\n",
    "for c in clusters_list:\n",
    "    interp = best_interp.get(int(float(c)), 'unknown')\n",
    "    cluster_labels.append(f\"Cluster {int(float(c))}\\n({interp})\")\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(cluster_labels)\n",
    "ax.set_ylabel('Probabilidade (%)')\n",
    "ax.set_title(f'Compara√ß√£o: P(fechar) vs P(tocar) - Target: {ga_config.target_return:.1%} em {ga_config.horizon} dias')\n",
    "ax.legend()\n",
    "\n",
    "# Adicionar valores nas barras\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height, f'{height:.1f}%',\n",
    "            ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height, f'{height:.1f}%',\n",
    "            ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Ratio touch/close\n",
    "print(\"\\n=== Ratio Touch/Close por Cluster ===\")\n",
    "for c in clusters_list:\n",
    "    data = dual_report['conditional_probabilities'][c]\n",
    "    ratio = data['touch_vs_close_ratio']\n",
    "    interp = best_interp.get(int(float(c)), 'unknown')\n",
    "    print(f\"Cluster {int(float(c))} ({interp}): {ratio:.2f}x mais prov√°vel tocar que fechar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Situa√ß√£o atual com an√°lise dual\n",
    "last_row = df_dual.iloc[-1]\n",
    "current_cluster = int(last_row['cluster'])\n",
    "current_interp = best_interp.get(current_cluster, 'unknown')\n",
    "\n",
    "current_data = dual_report['conditional_probabilities'][str(float(current_cluster))]\n",
    "current_prob_close = current_data['prob_close'] * 100\n",
    "current_prob_touch = current_data['prob_touch'] * 100\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SITUA√á√ÉO ATUAL - AN√ÅLISE DUAL\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nData: {last_row['date'].strftime('%Y-%m-%d')}\")\n",
    "print(f\"Pre√ßo: R$ {last_row['close']:.2f}\")\n",
    "print(f\"Regime: Cluster {current_cluster} ({current_interp.upper()})\")\n",
    "\n",
    "print(f\"\\nProbabilidade de atingir {ga_config.target_return:.1%} em {ga_config.horizon} dias:\")\n",
    "print(f\"  P(fechar ‚â• alvo): {current_prob_close:.1f}%\")\n",
    "print(f\"  P(tocar o alvo):  {current_prob_touch:.1f}%\")\n",
    "print(f\"  Ratio:            {current_prob_touch/current_prob_close:.2f}x\")\n",
    "\n",
    "print(f\"\\nüìà Interpreta√ß√£o:\")\n",
    "print(f\"  √â {current_prob_touch/current_prob_close:.1f}x mais prov√°vel o pre√ßo TOCAR o alvo\")\n",
    "print(f\"  do que FECHAR acima dele.\")\n",
    "print(f\"\\n  Isso √© √∫til para:\")\n",
    "print(f\"  - Op√ß√µes: P(tocar) relevante para barreiras knock-in/knock-out\")\n",
    "print(f\"  - Trading: P(tocar) para stop-loss e take-profit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclus√£o\n",
    "\n",
    "Este notebook demonstrou o fluxo completo do sistema QuantNote:\n",
    "\n",
    "1. **Configura√ß√£o** com valida√ß√£o via Pydantic\n",
    "2. **Obten√ß√£o de dados** do Yahoo Finance com rate limiting\n",
    "3. **Valida√ß√£o** de dados com m√∫ltiplos validators\n",
    "4. **Pipeline de calculadores** com resolu√ß√£o autom√°tica de depend√™ncias\n",
    "5. **Classifica√ß√£o de regimes** (manual e K-Means)\n",
    "6. **C√°lculo de probabilidades** condicionais\n",
    "7. **Visualiza√ß√£o** de distribui√ß√µes\n",
    "8. **Walk-forward validation** para evitar overfitting\n",
    "9. **Otimiza√ß√£o** com algoritmo gen√©tico\n",
    "10. **An√°lise dual** - P(fechar) vs P(tocar)\n",
    "\n",
    "### M√©tricas de Probabilidade\n",
    "\n",
    "- **P(fechar)**: Probabilidade de fechar acima do alvo no final do per√≠odo\n",
    "- **P(tocar)**: Probabilidade de atingir o alvo em algum momento durante o per√≠odo\n",
    "\n",
    "### Pr√≥ximos Passos\n",
    "\n",
    "- Testar com outros ativos\n",
    "- Ajustar par√¢metros do GA para busca mais ampla\n",
    "- Implementar novos indicadores (RSI, MACD, etc.)\n",
    "- Integrar com sistema de backtesting\n",
    "- Usar P(tocar) para otimiza√ß√£o de op√ß√µes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
