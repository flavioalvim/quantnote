{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QuantNote - Tutorial Did\u00e1tico\n",
    "\n",
    "## Sistema Quantitativo para Probabilidades de Retorno Condicionadas por Regime\n",
    "\n",
    "Este notebook demonstra passo a passo o funcionamento do sistema QuantNote.\n",
    "\n",
    "### Objetivo\n",
    "Calcular a probabilidade de um ativo atingir um retorno alvo em H per\u00edodos, condicionada ao regime de mercado atual.\n",
    "\n",
    "### Conceitos Principais\n",
    "1. **Log-Retornos**: Usamos log(P_t/P_{t-1}) pois s\u00e3o aditivos e sim\u00e9tricos\n",
    "2. **Slope (Inclina\u00e7\u00e3o)**: Tend\u00eancia calculada via regress\u00e3o linear do log-pre\u00e7o\n",
    "3. **Volatilidade**: Desvio padr\u00e3o dos retornos em janela m\u00f3vel\n",
    "4. **Regimes**: Estados do mercado (bull/bear/flat combinados com alta/baixa volatilidade)\n",
    "5. **K-Means**: Clustering para detectar regimes automaticamente\n",
    "6. **Walk-Forward**: Valida\u00e7\u00e3o para evitar overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 1: Setup e Imports\n",
    "\n",
    "Primeiro, configuramos o ambiente e importamos os m\u00f3dulos necess\u00e1rios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup do path para imports\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "\n",
    "# Imports padr\u00e3o\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Verificar se os imports funcionam\n",
    "print(\"Python path configurado!\")\n",
    "print(f\"Diret\u00f3rio de trabalho: {os.getcwd()}\")\n",
    "\n",
    "# Configura\u00e7\u00e3o de visualiza\u00e7\u00e3o\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.width', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 2: Configura\u00e7\u00e3o do Sistema\n",
    "\n",
    "O sistema usa Pydantic para validar configura\u00e7\u00f5es. Isso garante que par\u00e2metros inv\u00e1lidos sejam rejeitados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.settings import AnalysisConfig, InfrastructureConfig, Config\n",
    "from config.search_space import GAConfig, GASearchSpace\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURA\u00c7\u00c3O CENTRALIZADA\n",
    "# =============================================================================\n",
    "# Altere os par\u00e2metros abaixo conforme necess\u00e1rio.\n",
    "# Todos os notebooks usar\u00e3o estas configura\u00e7\u00f5es.\n",
    "\n",
    "# --- Ticker a analisar ---\n",
    "TICKER = \"BOVA11.SA\"\n",
    "\n",
    "# --- Par\u00e2metros de Predi\u00e7\u00e3o (usados pelo GA) ---\n",
    "TARGET_RETURN = 0.03   # Target: 1% de varia\u00e7\u00e3o\n",
    "HORIZON = 7            # Horizonte: 2 dias\n",
    "\n",
    "# --- Par\u00e2metros do GA Principal ---\n",
    "GA_POPULATION_SIZE = 100\n",
    "GA_GENERATIONS = 1000\n",
    "GA_N_FOLDS = 3\n",
    "GA_EARLY_STOPPING = True\n",
    "\n",
    "# --- Par\u00e2metros do GA para Multi-Target/Strike Grid (reduzido para demo) ---\n",
    "MULTI_GA_POPULATION_SIZE = 50\n",
    "MULTI_GA_GENERATIONS = 100\n",
    "\n",
    "# --- Par\u00e2metros de An\u00e1lise Explorat\u00f3ria (Etapas 1-11) ---\n",
    "ANALYSIS_WINDOW_SLOPE = 20\n",
    "ANALYSIS_WINDOW_VOLATILITY = 20\n",
    "ANALYSIS_WINDOW_ROLLING_RETURN = 20\n",
    "ANALYSIS_N_CLUSTERS = 6\n",
    "ANALYSIS_TARGET_RETURN = 0.05  # 5% para explora\u00e7\u00e3o did\u00e1tica\n",
    "\n",
    "# --- Par\u00e2metros de M\u00e9dias M\u00f3veis ---\n",
    "MA_FAST_PERIOD = 9     # M\u00e9dia m\u00f3vel r\u00e1pida\n",
    "MA_SLOW_PERIOD = 21    # M\u00e9dia m\u00f3vel lenta\n",
    "\n",
    "# =============================================================================\n",
    "# Criar objetos de configura\u00e7\u00e3o\n",
    "# =============================================================================\n",
    "\n",
    "# Config para an\u00e1lise explorat\u00f3ria (etapas iniciais do notebook)\n",
    "config = Config()\n",
    "config.analysis.future_return_periods = HORIZON\n",
    "config.analysis.window_slope = ANALYSIS_WINDOW_SLOPE\n",
    "config.analysis.window_volatility = ANALYSIS_WINDOW_VOLATILITY\n",
    "config.analysis.window_rolling_return = ANALYSIS_WINDOW_ROLLING_RETURN\n",
    "config.analysis.n_clusters = ANALYSIS_N_CLUSTERS\n",
    "config.analysis.target_return = ANALYSIS_TARGET_RETURN\n",
    "config.analysis.ma_fast_period = MA_FAST_PERIOD\n",
    "config.analysis.ma_slow_period = MA_SLOW_PERIOD\n",
    "\n",
    "# Config do GA para otimiza\u00e7\u00e3o principal\n",
    "ga_config = GAConfig(\n",
    "    target_return=TARGET_RETURN,\n",
    "    horizon=HORIZON,\n",
    "    population_size=GA_POPULATION_SIZE,\n",
    "    generations=GA_GENERATIONS,\n",
    "    n_folds=GA_N_FOLDS,\n",
    "    stability_penalty=0.1,\n",
    "    elite_size=2,\n",
    "    early_stopping=GA_EARLY_STOPPING,\n",
    ")\n",
    "\n",
    "# Config do GA para multi-target e strike grid (reduzido)\n",
    "multi_ga_config = GAConfig(\n",
    "    target_return=TARGET_RETURN,  # Ser\u00e1 sobrescrito pelo optimizer\n",
    "    horizon=HORIZON,\n",
    "    population_size=MULTI_GA_POPULATION_SIZE,\n",
    "    generations=MULTI_GA_GENERATIONS,\n",
    "    n_folds=GA_N_FOLDS,\n",
    "    early_stopping=GA_EARLY_STOPPING,\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# Exibir configura\u00e7\u00f5es\n",
    "# =============================================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"CONFIGURA\u00c7\u00c3O CENTRALIZADA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n\ud83d\udcca TICKER: {TICKER}\")\n",
    "\n",
    "print(f\"\\n\ud83c\udfaf Par\u00e2metros de Predi\u00e7\u00e3o:\")\n",
    "print(f\"   Target Return: {TARGET_RETURN:.1%}\")\n",
    "print(f\"   Horizonte: {HORIZON} dias\")\n",
    "\n",
    "print(f\"\\n\ud83e\uddec GA Principal:\")\n",
    "print(f\"   Popula\u00e7\u00e3o: {GA_POPULATION_SIZE}\")\n",
    "print(f\"   Gera\u00e7\u00f5es: {GA_GENERATIONS}\")\n",
    "print(f\"   Folds: {GA_N_FOLDS}\")\n",
    "print(f\"   Early Stopping: {GA_EARLY_STOPPING}\")\n",
    "\n",
    "print(f\"\\n\ud83c\udfaf GA Multi-Target/Strike Grid:\")\n",
    "print(f\"   Popula\u00e7\u00e3o: {MULTI_GA_POPULATION_SIZE}\")\n",
    "print(f\"   Gera\u00e7\u00f5es: {MULTI_GA_GENERATIONS}\")\n",
    "\n",
    "print(f\"\\n\ud83d\udcc8 An\u00e1lise Explorat\u00f3ria:\")\n",
    "print(f\"   Window Slope: {ANALYSIS_WINDOW_SLOPE}\")\n",
    "print(f\"   Window Volatility: {ANALYSIS_WINDOW_VOLATILITY}\")\n",
    "print(f\"   Clusters: {ANALYSIS_N_CLUSTERS}\")\n",
    "print(f\"   Target (explorat\u00f3rio): {ANALYSIS_TARGET_RETURN:.1%}\")\n",
    "\n",
    "print(f\"\\n\ud83d\udcc9 M\u00e9dias M\u00f3veis:\")\n",
    "print(f\"   MA R\u00e1pida: {MA_FAST_PERIOD} per\u00edodos\")\n",
    "print(f\"   MA Lenta: {MA_SLOW_PERIOD} per\u00edodos\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 3: Obten\u00e7\u00e3o de Dados\n",
    "\n",
    "Usamos `YahooDataSource` para baixar dados OHLCV. O sistema tem rate limiting para evitar bloqueio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.infrastructure.yahoo_data_source import YahooDataSource\n",
    "from src.infrastructure.parquet_repository import ParquetRepository\n",
    "from src.infrastructure.file_logger import FileLogger, NullLogger\n",
    "\n",
    "# Criar logger (usar NullLogger para menos output)\n",
    "logger = NullLogger()  # ou FileLogger(\"quantnote\") para logs detalhados\n",
    "\n",
    "# Data source e repository\n",
    "data_source = YahooDataSource(calls_per_minute=5, logger=logger)\n",
    "repository = ParquetRepository(data_dir=\"../data\", logger=logger)\n",
    "\n",
    "# Usar ticker da configura\u00e7\u00e3o centralizada\n",
    "ticker = TICKER\n",
    "\n",
    "print(f\"Buscando dados para {ticker}...\")\n",
    "\n",
    "# Verificar se dados no cache est\u00e3o atualizados\n",
    "is_current, last_date = repository.is_data_current(ticker, max_age_days=1)\n",
    "\n",
    "if is_current:\n",
    "    print(f\"\u2705 Cache atualizado (\u00faltima data: {last_date.date()})\")\n",
    "    df = repository.load(ticker)\n",
    "else:\n",
    "    if last_date:\n",
    "        print(f\"\u26a0\ufe0f  Cache desatualizado (\u00faltima data: {last_date.date()})\")\n",
    "    else:\n",
    "        print(\"\ud83d\udce5 Dados n\u00e3o encontrados no cache.\")\n",
    "    \n",
    "    print(\"Baixando dados atualizados do Yahoo Finance...\")\n",
    "    df = data_source.fetch_ohlcv(ticker)\n",
    "    \n",
    "    # Limpar arquivos antigos e salvar novos dados\n",
    "    deleted = repository.delete_old_files(ticker, keep_latest=0)\n",
    "    if deleted:\n",
    "        print(f\"\ud83d\uddd1\ufe0f  {deleted} arquivo(s) antigo(s) removido(s)\")\n",
    "    \n",
    "    repository.save(df, ticker)\n",
    "    print(\"\u2705 Dados atualizados salvos no cache.\")\n",
    "\n",
    "print(f\"\\n=== Dados Obtidos ===\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Per\u00edodo: {df['date'].min().date()} a {df['date'].max().date()}\")\n",
    "print(f\"\\nPrimeiras linhas:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 4: Valida\u00e7\u00e3o de Dados\n",
    "\n",
    "Antes de processar, validamos os dados para garantir qualidade.\n",
    "\n",
    "O sistema usa o padr\u00e3o **Composite** para combinar m\u00faltiplos validadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.infrastructure.validators import create_default_validator\n",
    "\n",
    "# Criar validador composto\n",
    "validator = create_default_validator(\n",
    "    min_length=config.analysis.min_data_points,\n",
    "    max_window=max(config.analysis.window_slope, config.analysis.window_volatility)\n",
    ")\n",
    "\n",
    "# Executar valida\u00e7\u00e3o\n",
    "validation = validator.validate(df)\n",
    "\n",
    "print(\"=== Resultado da Valida\u00e7\u00e3o ===\")\n",
    "print(f\"V\u00e1lido: {'SIM' if validation.is_valid else 'N\u00c3O'}\")\n",
    "\n",
    "if validation.errors:\n",
    "    print(f\"\\nERROS:\")\n",
    "    for error in validation.errors:\n",
    "        print(f\"  - {error}\")\n",
    "\n",
    "if validation.warnings:\n",
    "    print(f\"\\nAVISOS:\")\n",
    "    for warning in validation.warnings:\n",
    "        print(f\"  - {warning}\")\n",
    "\n",
    "if validation.is_valid and not validation.warnings:\n",
    "    print(\"Todos os testes passaram sem avisos!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 5: Calculadores Individuais\n",
    "\n",
    "Vamos explorar cada calculador individualmente para entender o que faz.\n",
    "\n",
    "Cada calculador implementa `IColumnCalculator` e segue o princ\u00edpio de **Single Responsibility**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.calculators.log_price_calculator import LogPriceCalculator\n",
    "\n",
    "# 5.1 - Log Price Calculator\n",
    "log_price_calc = LogPriceCalculator()\n",
    "\n",
    "print(\"=== LogPriceCalculator ===\")\n",
    "print(f\"Nome: {log_price_calc.name}\")\n",
    "print(f\"Colunas requeridas: {log_price_calc.required_columns}\")\n",
    "print(f\"Colunas produzidas: {log_price_calc.output_columns}\")\n",
    "\n",
    "# Aplicar\n",
    "df_step1 = log_price_calc.calculate(df)\n",
    "\n",
    "# Visualizar resultado\n",
    "print(f\"\\nFormula: log_close = ln(close)\")\n",
    "print(f\"\\nExemplo:\")\n",
    "print(df_step1[['date', 'close', 'log_close']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.calculators.log_return_calculator import LogReturnCalculator\n",
    "\n",
    "# 5.2 - Log Return Calculator\n",
    "log_return_calc = LogReturnCalculator(window=config.analysis.window_rolling_return)\n",
    "\n",
    "print(\"=== LogReturnCalculator ===\")\n",
    "print(f\"Nome: {log_return_calc.name}\")\n",
    "print(f\"Colunas requeridas: {log_return_calc.required_columns}\")\n",
    "print(f\"Colunas produzidas: {log_return_calc.output_columns}\")\n",
    "\n",
    "# Aplicar\n",
    "df_step2 = log_return_calc.calculate(df_step1)\n",
    "\n",
    "print(f\"\\nFormulas:\")\n",
    "print(f\"  log_return = ln(close_t / close_{{t-1}})\")\n",
    "print(f\"  log_return_rolling_20 = sum(log_return over 20 days)\")\n",
    "print(f\"\\nExemplo:\")\n",
    "print(df_step2[['date', 'close', 'log_return', f'log_return_rolling_{config.analysis.window_rolling_return}']].head(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.calculators.volatility_calculator import VolatilityCalculator\n",
    "\n",
    "# 5.3 - Volatility Calculator\n",
    "vol_calc = VolatilityCalculator(window=config.analysis.window_volatility)\n",
    "\n",
    "print(\"=== VolatilityCalculator ===\")\n",
    "print(f\"Nome: {vol_calc.name}\")\n",
    "print(f\"Colunas requeridas: {vol_calc.required_columns}\")\n",
    "print(f\"Colunas produzidas: {vol_calc.output_columns}\")\n",
    "\n",
    "# Aplicar\n",
    "df_step3 = vol_calc.calculate(df_step2)\n",
    "\n",
    "print(f\"\\nFormula: volatility = std(log_return over {config.analysis.window_volatility} days)\")\n",
    "print(f\"\\nExemplo:\")\n",
    "print(df_step3[['date', 'log_return', f'volatility_{config.analysis.window_volatility}']].tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.calculators.slope_calculator import SlopeCalculator\n",
    "\n",
    "# 5.4 - Slope Calculator\n",
    "slope_calc = SlopeCalculator(window=config.analysis.window_slope)\n",
    "\n",
    "print(\"=== SlopeCalculator ===\")\n",
    "print(f\"Nome: {slope_calc.name}\")\n",
    "print(f\"Colunas requeridas: {slope_calc.required_columns}\")\n",
    "print(f\"Colunas produzidas: {slope_calc.output_columns}\")\n",
    "\n",
    "# Aplicar\n",
    "df_step4 = slope_calc.calculate(df_step3)\n",
    "\n",
    "print(f\"\\nFormula: slope = coef angular da regress\u00e3o linear de log_close sobre {config.analysis.window_slope} dias\")\n",
    "print(f\"\\nInterpreta\u00e7\u00e3o:\")\n",
    "print(f\"  slope > 0: tend\u00eancia de alta\")\n",
    "print(f\"  slope < 0: tend\u00eancia de baixa\")\n",
    "print(f\"  slope \u2248 0: mercado lateral\")\n",
    "print(f\"\\nExemplo:\")\n",
    "print(df_step4[['date', 'log_close', f'slope_{config.analysis.window_slope}']].tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.calculators.ma_distance_calculator import MADistanceCalculator\n",
    "\n",
    "# 5.5 - MA Distance Calculator\n",
    "ma_dist_calc = MADistanceCalculator(\n",
    "    fast_period=config.analysis.ma_fast_period,\n",
    "    slow_period=config.analysis.ma_slow_period\n",
    ")\n",
    "\n",
    "print(\"=== MADistanceCalculator ===\")\n",
    "print(f\"Nome: {ma_dist_calc.name}\")\n",
    "print(f\"Colunas requeridas: {ma_dist_calc.required_columns}\")\n",
    "print(f\"Colunas produzidas: {ma_dist_calc.output_columns}\")\n",
    "\n",
    "# Aplicar\n",
    "df_step4b = ma_dist_calc.calculate(df_step4)\n",
    "\n",
    "ma_col = f'ma_dist_{config.analysis.ma_fast_period}_{config.analysis.ma_slow_period}'\n",
    "\n",
    "print(f\"\\nFormula:\")\n",
    "print(f\"  MA_fast = SMA(close, {config.analysis.ma_fast_period})\")\n",
    "print(f\"  MA_slow = SMA(close, {config.analysis.ma_slow_period})\")\n",
    "print(f\"  distance = MA_fast - MA_slow\")\n",
    "print(f\"  {ma_col} = normalize(distance, min=-1, max=1)\")\n",
    "\n",
    "print(f\"\\nInterpreta\u00e7\u00e3o:\")\n",
    "print(f\"  > 0: tend\u00eancia de alta (MA r\u00e1pida > MA lenta)\")\n",
    "print(f\"  < 0: tend\u00eancia de baixa (MA r\u00e1pida < MA lenta)\")\n",
    "print(f\"  \u2248 0: m\u00e9dias cruzando/convergindo\")\n",
    "\n",
    "print(f\"\\nExemplo:\")\n",
    "print(df_step4b[['date', 'close', ma_col]].tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.calculators.future_return_calculator import FutureReturnCalculator\n",
    "\n",
    "# 5.6 - Future Return Calculator\n",
    "future_calc = FutureReturnCalculator(horizon=config.analysis.future_return_periods)\n",
    "\n",
    "print(\"=== FutureReturnCalculator ===\")\n",
    "print(f\"Nome: {future_calc.name}\")\n",
    "print(f\"Colunas requeridas: {future_calc.required_columns}\")\n",
    "print(f\"Colunas produzidas: {future_calc.output_columns}\")\n",
    "\n",
    "# Aplicar\n",
    "df_step5 = future_calc.calculate(df_step4)\n",
    "\n",
    "print(f\"\\nFormula: log_return_future_{config.analysis.future_return_periods} = ln(close_{{t+{config.analysis.future_return_periods}}} / close_t)\")\n",
    "print(f\"\\nNOTA: Esta coluna \u00e9 a vari\u00e1vel TARGET que queremos prever!\")\n",
    "print(f\"\\nExemplo:\")\n",
    "print(df_step5[['date', 'close', f'log_return_future_{config.analysis.future_return_periods}']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 6: Pipeline com Resolu\u00e7\u00e3o Autom\u00e1tica de Depend\u00eancias\n",
    "\n",
    "O `CalculatorPipeline` usa **topological sort** para ordenar os calculadores automaticamente.\n",
    "\n",
    "Isso implementa o princ\u00edpio **Open/Closed** - podemos adicionar calculadores sem modificar o pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.calculators.pipeline import CalculatorPipeline\n",
    "from src.calculators.log_price_calculator import LogPriceCalculator\n",
    "from src.calculators.log_return_calculator import LogReturnCalculator\n",
    "from src.calculators.future_return_calculator import FutureReturnCalculator\n",
    "from src.calculators.volatility_calculator import VolatilityCalculator\n",
    "from src.calculators.slope_calculator import SlopeCalculator\n",
    "from src.calculators.ma_distance_calculator import MADistanceCalculator\n",
    "\n",
    "# Criar pipeline (note que a ordem n\u00e3o importa - ser\u00e1 resolvida automaticamente)\n",
    "pipeline = CalculatorPipeline([\n",
    "    SlopeCalculator(window=config.analysis.window_slope),      # Depende de log_close\n",
    "    LogReturnCalculator(window=config.analysis.window_rolling_return),  # Depende de close\n",
    "    VolatilityCalculator(window=config.analysis.window_volatility),     # Depende de log_return\n",
    "    LogPriceCalculator(),                                       # Depende de close\n",
    "    FutureReturnCalculator(horizon=config.analysis.future_return_periods),  # Depende de close\n",
    "    MADistanceCalculator(                                       # Depende de close\n",
    "        fast_period=config.analysis.ma_fast_period,\n",
    "        slow_period=config.analysis.ma_slow_period\n",
    "    )\n",
    "], logger=logger)\n",
    "\n",
    "# Executar pipeline\n",
    "df_analysis = pipeline.run(df)\n",
    "\n",
    "print(\"=== Pipeline Executado ===\")\n",
    "print(f\"Ordem de execu\u00e7\u00e3o: {pipeline.get_execution_order()}\")\n",
    "print(f\"\\nColunas originais: {len(df.columns)}\")\n",
    "print(f\"Colunas ap\u00f3s pipeline: {len(df_analysis.columns)}\")\n",
    "print(f\"\\nNovas colunas: {list(pipeline.get_all_output_columns())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar resultado do pipeline\n",
    "print(\"=== Dados Ap\u00f3s Pipeline ===\")\n",
    "df_analysis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 7: Classifica\u00e7\u00e3o Manual de Regimes\n",
    "\n",
    "Uma abordagem \u00e9 usar thresholds manuais para classificar regimes baseado em slope e volatilidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analysis.regime_classifier import ManualRegimeClassifier\n",
    "\n",
    "# Nomes das colunas\n",
    "slope_col = f'slope_{config.analysis.window_slope}'\n",
    "vol_col = f'volatility_{config.analysis.window_volatility}'\n",
    "\n",
    "# Criar classificador manual (thresholds autom\u00e1ticos)\n",
    "manual_classifier = ManualRegimeClassifier(\n",
    "    slope_column=slope_col,\n",
    "    volatility_column=vol_col\n",
    ")\n",
    "\n",
    "# Classificar\n",
    "df_manual = manual_classifier.classify(df_analysis)\n",
    "\n",
    "# Resultados\n",
    "print(\"=== Classifica\u00e7\u00e3o Manual de Regimes ===\")\n",
    "print(f\"\\nThresholds usados: {manual_classifier.get_thresholds()}\")\n",
    "print(f\"\\nDistribui\u00e7\u00e3o de regimes:\")\n",
    "print(df_manual['regime'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar distribui\u00e7\u00e3o por regime\n",
    "regime_counts = df_manual['regime'].value_counts()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "colors = {\n",
    "    'bull_high_vol': 'lightgreen',\n",
    "    'bull_low_vol': 'darkgreen',\n",
    "    'bear_high_vol': 'lightcoral',\n",
    "    'bear_low_vol': 'darkred',\n",
    "    'flat_high_vol': 'yellow',\n",
    "    'flat_low_vol': 'gold'\n",
    "}\n",
    "bar_colors = [colors.get(r, 'gray') for r in regime_counts.index]\n",
    "regime_counts.plot(kind='bar', ax=ax, color=bar_colors, edgecolor='black')\n",
    "ax.set_title('Distribui\u00e7\u00e3o de Regimes (Classifica\u00e7\u00e3o Manual)')\n",
    "ax.set_xlabel('Regime')\n",
    "ax.set_ylabel('Frequ\u00eancia')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 8: Classifica\u00e7\u00e3o com K-Means\n",
    "\n",
    "K-Means detecta regimes automaticamente baseado em m\u00faltiplas features.\n",
    "\n",
    "Isso \u00e9 mais robusto que thresholds manuais pois considera todas as features simultaneamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analysis.kmeans_regimes import KMeansRegimeClassifier\n",
    "\n",
    "# Criar classificador K-Means\n",
    "kmeans = KMeansRegimeClassifier(\n",
    "    n_clusters=config.analysis.n_clusters,\n",
    "    logger=logger\n",
    ")\n",
    "\n",
    "# Fit e Predict\n",
    "df_kmeans = kmeans.fit_predict(df_analysis)\n",
    "\n",
    "print(\"=== Classifica\u00e7\u00e3o K-Means ===\")\n",
    "print(f\"\\nFeatures usadas: {kmeans.feature_columns}\")\n",
    "print(f\"N\u00famero de clusters: {config.analysis.n_clusters}\")\n",
    "print(f\"\\nDistribui\u00e7\u00e3o de clusters:\")\n",
    "print(df_kmeans['cluster'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estat\u00edsticas por cluster\n",
    "future_col = f'log_return_future_{config.analysis.future_return_periods}'\n",
    "stats = kmeans.compute_statistics(df_kmeans, future_col)\n",
    "interpretations = kmeans.interpret_clusters(df_kmeans, slope_col)\n",
    "\n",
    "print(\"=== Estat\u00edsticas por Cluster ===\")\n",
    "for stat in stats:\n",
    "    interp = interpretations.get(stat.cluster_id, 'unknown')\n",
    "    print(f\"\\nCluster {stat.cluster_id} ({interp.upper()}):\")\n",
    "    print(f\"  Observa\u00e7\u00f5es: {stat.count} ({stat.percentage:.1f}%)\")\n",
    "    print(f\"  Retorno futuro m\u00e9dio: {stat.future_return_mean:.4f}\")\n",
    "    print(f\"  Desvio padr\u00e3o: {stat.future_return_std:.4f}\")\n",
    "    print(f\"  Features m\u00e9dias: {stat.feature_means}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 9: C\u00e1lculo de Probabilidades\n",
    "\n",
    "Agora calculamos a probabilidade de atingir o retorno alvo, condicionada por regime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analysis.probability_calculator import ProbabilityCalculator\n",
    "\n",
    "# Usando classifica\u00e7\u00e3o manual\n",
    "prob_calc_manual = ProbabilityCalculator(\n",
    "    future_return_column=future_col,\n",
    "    target_return=config.analysis.target_return,\n",
    "    regime_column='regime'\n",
    ")\n",
    "\n",
    "# Gerar relat\u00f3rio completo\n",
    "report = prob_calc_manual.generate_report(df_manual)\n",
    "\n",
    "print(\"=== Relat\u00f3rio de Probabilidades (Regimes Manuais) ===\")\n",
    "print(f\"\\nRetorno alvo: {report['target_return']:.1%}\")\n",
    "print(f\"Log-retorno alvo: {report['log_target']:.4f}\")\n",
    "print(f\"\\nProbabilidade incondicional: {report['raw_probability_pct']:.2f}%\")\n",
    "\n",
    "print(f\"\\nProbabilidades condicionais:\")\n",
    "for regime, data in report['conditional_probabilities'].items():\n",
    "    print(f\"  {regime}:\")\n",
    "    print(f\"    P(hit) = {data['probability_pct']:.2f}%\")\n",
    "    print(f\"    n = {data['count']}\")\n",
    "    print(f\"    retorno m\u00e9dio = {data['mean_return']:.4f}\")\n",
    "\n",
    "print(f\"\\nM\u00e9tricas de separa\u00e7\u00e3o:\")\n",
    "print(f\"  Delta P: {report['separation_metrics']['delta_p']:.4f}\")\n",
    "print(f\"  (diferen\u00e7a entre maior e menor probabilidade)\")\n",
    "print(f\"  Information Ratio: {report['separation_metrics']['information_ratio']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando classifica\u00e7\u00e3o K-Means\n",
    "prob_calc_kmeans = ProbabilityCalculator(\n",
    "    future_return_column=future_col,\n",
    "    target_return=config.analysis.target_return,\n",
    "    regime_column='cluster'\n",
    ")\n",
    "\n",
    "report_kmeans = prob_calc_kmeans.generate_report(df_kmeans)\n",
    "\n",
    "print(\"=== Relat\u00f3rio de Probabilidades (K-Means) ===\")\n",
    "print(f\"\\nRetorno alvo: {report_kmeans['target_return']:.1%}\")\n",
    "print(f\"\\nProbabilidade incondicional: {report_kmeans['raw_probability_pct']:.2f}%\")\n",
    "\n",
    "print(f\"\\nProbabilidades por cluster:\")\n",
    "for cluster_id, data in sorted(report_kmeans['conditional_probabilities'].items()):\n",
    "    interp = interpretations.get(int(float(cluster_id)), 'unknown')\n",
    "    print(f\"  Cluster {cluster_id} ({interp}): P(hit) = {data['probability_pct']:.2f}% (n={data['count']})\")\n",
    "\n",
    "print(f\"\\nDelta P: {report_kmeans['separation_metrics']['delta_p']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 10: Visualiza\u00e7\u00f5es\n",
    "\n",
    "Visualizamos a distribui\u00e7\u00e3o de retornos por regime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.visualization.histogram_plotter import HistogramPlotter, PriceRegimePlotter\n",
    "\n",
    "# Histograma geral\n",
    "hist_plotter = HistogramPlotter(\n",
    "    return_column=future_col,\n",
    "    regime_column='regime'\n",
    ")\n",
    "\n",
    "fig = hist_plotter.plot(df_manual)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramas por regime\n",
    "fig = hist_plotter.plot_by_regime(df_manual, target_return=config.analysis.target_return)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre\u00e7o com background de regime\n",
    "df_manual_indexed = df_manual.set_index('date')\n",
    "\n",
    "price_plotter = PriceRegimePlotter(regime_column='regime')\n",
    "fig = price_plotter.plot(df_manual_indexed)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 11: Walk-Forward Validation\n",
    "\n",
    "Para evitar overfitting, usamos walk-forward validation.\n",
    "\n",
    "Isso simula como o modelo performaria em tempo real, sempre treinando no passado e testando no futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analysis.time_series_splitter import TimeSeriesSplitter\n",
    "\n",
    "# Criar splitter\n",
    "splitter = TimeSeriesSplitter(train_ratio=0.7)\n",
    "\n",
    "# Demonstrar walk-forward splits\n",
    "print(\"=== Walk-Forward Splits ===\")\n",
    "for split in splitter.walk_forward_split(df, n_folds=5, min_train_size=252):\n",
    "    train_start = split.train['date'].min().date()\n",
    "    train_end = split.train['date'].max().date()\n",
    "    test_start = split.test['date'].min().date()\n",
    "    test_end = split.test['date'].max().date()\n",
    "    \n",
    "    print(f\"\\nFold {split.fold}:\")\n",
    "    print(f\"  Train: {train_start} a {train_end} ({len(split.train)} obs)\")\n",
    "    print(f\"  Test:  {test_start} a {test_end} ({len(split.test)} obs)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 12: Otimiza\u00e7\u00e3o com Algoritmo Gen\u00e9tico (Otimizado)\n",
    "\n",
    "O GA busca os melhores par\u00e2metros automaticamente.\n",
    "\n",
    "**Otimiza\u00e7\u00f5es implementadas:**\n",
    "1. **Paraleliza\u00e7\u00e3o**: Avalia\u00e7\u00e3o de fitness usa m\u00faltiplos cores CPU\n",
    "2. **Cache**: Cromossomos id\u00eanticos n\u00e3o s\u00e3o reavaliados\n",
    "3. **Numba**: C\u00e1lculo de slope ~10-50x mais r\u00e1pido (ap\u00f3s warm-up)\n",
    "4. **KMeans otimizado**: Algoritmo Lloyd para melhor performance\n",
    "\n",
    "**NOTA sobre Numba**: A primeira execu\u00e7\u00e3o ser\u00e1 mais lenta devido \u00e0 compila\u00e7\u00e3o JIT. Execu\u00e7\u00f5es subsequentes ser\u00e3o significativamente mais r\u00e1pidas. O cache do Numba persiste entre sess\u00f5es.\n",
    "\n",
    "**NOTA**: Esta etapa \u00e9 computacionalmente intensiva. Reduzimos os par\u00e2metros para demonstra\u00e7\u00e3o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.calculators.slope_calculator import SlopeCalculator\n",
    "import multiprocessing as mp\n",
    "\n",
    "# Verificar otimiza\u00e7\u00f5es dispon\u00edveis\n",
    "print(\"=== Verifica\u00e7\u00e3o de Otimiza\u00e7\u00f5es ===\")\n",
    "print(f\"Numba dispon\u00edvel para SlopeCalculator: {SlopeCalculator.is_numba_available()}\")\n",
    "print(f\"CPUs dispon\u00edveis para paraleliza\u00e7\u00e3o: {mp.cpu_count()}\")\n",
    "\n",
    "# ga_config j\u00e1 definido na c\u00e9lula de configura\u00e7\u00e3o centralizada\n",
    "print(\"\\n=== Configura\u00e7\u00e3o do GA (da c\u00e9lula centralizada) ===\")\n",
    "print(f\"Target Return: {ga_config.target_return:.1%}\")\n",
    "print(f\"Horizonte: {ga_config.horizon} dias\")\n",
    "print(f\"Popula\u00e7\u00e3o: {ga_config.population_size}\")\n",
    "print(f\"Gera\u00e7\u00f5es: {ga_config.generations}\")\n",
    "print(f\"Folds: {ga_config.n_folds}\")\n",
    "print(f\"Early Stopping: {ga_config.early_stopping}\")\n",
    "\n",
    "# Estimativa de tempo\n",
    "tempo_por_gen = ga_config.population_size * 0.035  # ~0.035s por cromossomo\n",
    "tempo_total = ga_config.generations * tempo_por_gen\n",
    "print(f\"\\nTempo estimado: {tempo_total/60:.1f} minutos\")\n",
    "print(\"\\nNOTA: Use Ctrl+C para interromper e salvar checkpoint a qualquer momento.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.optimization.genetic_algorithm import GeneticAlgorithm, GACheckpoint\n",
    "from src.optimization.progress_callback import LiveProgressCallback\n",
    "\n",
    "# Criar callback de progresso visual\n",
    "progress_callback = LiveProgressCallback(\n",
    "    total_generations=ga_config.generations,\n",
    "    population_size=ga_config.population_size,\n",
    "    update_every=1\n",
    ")\n",
    "\n",
    "# Executar GA\n",
    "# NOTA: parallel=False \u00e9 mais est\u00e1vel em Jupyter notebooks\n",
    "ga = GeneticAlgorithm(\n",
    "    df, \n",
    "    ga_config, \n",
    "    logger=logger,\n",
    "    progress_callback=progress_callback,\n",
    "    n_workers=None\n",
    ")\n",
    "\n",
    "try:\n",
    "    result = ga.run(\n",
    "        verbose=False,\n",
    "        parallel=False,  # Desativado para evitar problemas no Jupyter\n",
    "        auto_checkpoint_path=\"ga_checkpoint.json\",\n",
    "        checkpoint_every=10\n",
    "    )\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nInterrompido! Salvando checkpoint...\")\n",
    "    ga.save_checkpoint(\"ga_checkpoint.json\")\n",
    "    print(\"Checkpoint salvo em 'ga_checkpoint.json'\")\n",
    "    print(\"Para retomar: checkpoint = GACheckpoint.load('ga_checkpoint.json')\")\n",
    "    raise\n",
    "\n",
    "progress_callback.finalize()\n",
    "\n",
    "print(\"\\n=== Melhores Par\u00e2metros Encontrados ===\")\n",
    "best = result.best_chromosome\n",
    "print(f\"  Window Slope: {best.window_slope}\")\n",
    "print(f\"  Window Volatility: {best.window_volatility}\")\n",
    "print(f\"  Window Rolling Return: {best.window_rolling_return}\")\n",
    "print(f\"  N Clusters: {best.n_clusters}\")\n",
    "print(f\"  MA Fast Period: {best.ma_fast_period}\")\n",
    "print(f\"  MA Slow Period: {best.ma_slow_period}\")\n",
    "print(f\"  Use Volatility: {best.use_volatility}\")\n",
    "print(f\"  Use Rolling Return: {best.use_rolling_return}\")\n",
    "print(f\"  Use MA Distance: {best.use_ma_distance}\")\n",
    "\n",
    "print(f\"\\nPar\u00e2metros fixos (da configura\u00e7\u00e3o):\")\n",
    "print(f\"  Target Return: {ga_config.target_return:.2%}\")\n",
    "print(f\"  Horizon: {ga_config.horizon} dias\")\n",
    "\n",
    "print(f\"\\nM\u00e9tricas:\")\n",
    "print(f\"  Fitness: {result.best_fitness:.4f}\")\n",
    "print(f\"  Delta P (test): {result.best_metrics.delta_p_test:.4f}\")\n",
    "print(f\"  Overfitting Ratio: {result.best_metrics.overfitting_ratio:.2f}\")\n",
    "\n",
    "print(f\"\\nEstat\u00edsticas:\")\n",
    "print(f\"  Total avalia\u00e7\u00f5es: {result.all_evaluations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar evolu\u00e7\u00e3o do fitness\n",
    "generations = [h[0] for h in result.history]\n",
    "best_fitness = [h[1] for h in result.history]\n",
    "mean_fitness = [h[2] for h in result.history]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(generations, best_fitness, 'b-', label='Best Fitness', linewidth=2)\n",
    "ax.plot(generations, mean_fitness, 'g--', label='Mean Fitness', alpha=0.7)\n",
    "ax.set_xlabel('Generation')\n",
    "ax.set_ylabel('Fitness')\n",
    "ax.set_title('Evolu\u00e7\u00e3o do Algoritmo Gen\u00e9tico')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 13: Aplicar Melhores Par\u00e2metros\n",
    "\n",
    "Agora aplicamos os par\u00e2metros otimizados e recalculamos as probabilidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.optimization.calculator_factory import CalculatorFactory\n",
    "\n",
    "# Factory para criar pipeline com os melhores par\u00e2metros\n",
    "# horizon vem da configura\u00e7\u00e3o, n\u00e3o do cromossomo\n",
    "factory = CalculatorFactory(horizon=ga_config.horizon)\n",
    "best_pipeline = factory.create_pipeline(best)\n",
    "feature_cols = factory.get_feature_columns(best)\n",
    "future_col_best = factory.get_future_return_column()\n",
    "\n",
    "# Processar dados\n",
    "df_best = best_pipeline.run(df)\n",
    "\n",
    "# Clustering\n",
    "best_kmeans = KMeansRegimeClassifier(\n",
    "    n_clusters=best.n_clusters,\n",
    "    feature_columns=feature_cols\n",
    ")\n",
    "df_best = best_kmeans.fit_predict(df_best)\n",
    "\n",
    "# Probabilidades (target_return vem da configura\u00e7\u00e3o)\n",
    "best_prob = ProbabilityCalculator(\n",
    "    future_return_column=future_col_best,\n",
    "    target_return=ga_config.target_return,\n",
    "    regime_column='cluster'\n",
    ")\n",
    "\n",
    "best_report = best_prob.generate_report(df_best)\n",
    "\n",
    "print(\"=== Relat\u00f3rio com Par\u00e2metros Otimizados ===\")\n",
    "print(f\"\\nRetorno alvo: {ga_config.target_return:.1%}\")\n",
    "print(f\"Horizonte: {ga_config.horizon} dias\")\n",
    "print(f\"\\nProbabilidade incondicional: {best_report['raw_probability_pct']:.2f}%\")\n",
    "\n",
    "# Interpretar clusters\n",
    "slope_col_best = f'slope_{best.window_slope}'\n",
    "best_interp = best_kmeans.interpret_clusters(df_best, slope_col_best)\n",
    "\n",
    "print(f\"\\nProbabilidades por cluster:\")\n",
    "for cluster_id, data in sorted(best_report['conditional_probabilities'].items()):\n",
    "    interp = best_interp.get(int(float(cluster_id)), 'unknown')\n",
    "    print(f\"  Cluster {cluster_id} ({interp.upper()}): P(hit) = {data['probability_pct']:.2f}% (n={data['count']})\")\n",
    "\n",
    "print(f\"\\nDelta P: {best_report['separation_metrics']['delta_p']:.4f}\")\n",
    "print(f\"Information Ratio: {best_report['separation_metrics']['information_ratio']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 14: Visualiza\u00e7\u00f5es com Par\u00e2metros Otimizados\n",
    "\n",
    "Agora repetimos todas as visualiza\u00e7\u00f5es usando os par\u00e2metros do indiv\u00edduo vencedor do GA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estat\u00edsticas por cluster com par\u00e2metros otimizados\n",
    "stats_best = best_kmeans.compute_statistics(df_best, future_col_best)\n",
    "\n",
    "print(\"=== Estat\u00edsticas por Cluster (Par\u00e2metros Otimizados) ===\")\n",
    "for stat in stats_best:\n",
    "    interp = best_interp.get(stat.cluster_id, 'unknown')\n",
    "    print(f\"\\nCluster {stat.cluster_id} ({interp.upper()}):\")\n",
    "    print(f\"  Observa\u00e7\u00f5es: {stat.count} ({stat.percentage:.1f}%)\")\n",
    "    print(f\"  Retorno futuro m\u00e9dio: {stat.future_return_mean:.4f}\")\n",
    "    print(f\"  Desvio padr\u00e3o: {stat.future_return_std:.4f}\")\n",
    "    print(f\"  Features m\u00e9dias: {stat.feature_means}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograma de retornos com par\u00e2metros otimizados\n",
    "hist_plotter_best = HistogramPlotter(\n",
    "    return_column=future_col_best,\n",
    "    regime_column='cluster'\n",
    ")\n",
    "\n",
    "fig = hist_plotter_best.plot(df_best)\n",
    "plt.suptitle(f'Distribui\u00e7\u00e3o de Retornos Futuros ({ga_config.horizon} dias) - Par\u00e2metros Otimizados', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramas por cluster com linha do target\n",
    "fig = hist_plotter_best.plot_by_regime(df_best, target_return=ga_config.target_return)\n",
    "plt.suptitle(f'Distribui\u00e7\u00e3o por Cluster - Target: {ga_config.target_return:.1%} em {ga_config.horizon} dias', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre\u00e7o com background de cluster otimizado\n",
    "df_best_indexed = df_best.set_index('date')\n",
    "\n",
    "price_plotter_best = PriceRegimePlotter(regime_column='cluster')\n",
    "fig = price_plotter_best.plot(df_best_indexed)\n",
    "plt.suptitle('Pre\u00e7o com Regimes Otimizados pelo GA', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr\u00e1fico de barras: Probabilidade por Cluster\n",
    "clusters = []\n",
    "probs = []\n",
    "colors = []\n",
    "color_map = {'bull': 'green', 'bear': 'red', 'flat': 'gold'}\n",
    "\n",
    "for cluster_id, data in sorted(best_report['conditional_probabilities'].items()):\n",
    "    interp = best_interp.get(int(float(cluster_id)), 'flat')\n",
    "    clusters.append(f\"Cluster {int(float(cluster_id))}\\n({interp})\")\n",
    "    probs.append(data['probability_pct'])\n",
    "    colors.append(color_map.get(interp, 'gray'))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "bars = ax.bar(clusters, probs, color=colors, edgecolor='black', alpha=0.8)\n",
    "\n",
    "# Linha horizontal para probabilidade incondicional\n",
    "ax.axhline(y=best_report['raw_probability_pct'], color='blue', linestyle='--', \n",
    "           linewidth=2, label=f\"P incondicional: {best_report['raw_probability_pct']:.1f}%\")\n",
    "\n",
    "# Adicionar valores nas barras\n",
    "for bar, prob in zip(bars, probs):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
    "            f'{prob:.1f}%', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "ax.set_ylabel('Probabilidade (%)')\n",
    "ax.set_title(f'Probabilidade de Atingir {ga_config.target_return:.1%} em {ga_config.horizon} dias por Cluster')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nDelta P (separa\u00e7\u00e3o): {best_report['separation_metrics']['delta_p']:.4f}\")\n",
    "print(f\"Melhor cluster: {max(best_report['conditional_probabilities'].items(), key=lambda x: x[1]['probability_pct'])[0]}\")\n",
    "print(f\"Pior cluster: {min(best_report['conditional_probabilities'].items(), key=lambda x: x[1]['probability_pct'])[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar regime atual e probabilidade\n",
    "last_row = df_best.iloc[-1]\n",
    "current_cluster = int(last_row['cluster'])\n",
    "current_interp = best_interp.get(current_cluster, 'unknown')\n",
    "current_prob = best_report['conditional_probabilities'][str(float(current_cluster))]['probability_pct']\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SITUA\u00c7\u00c3O ATUAL\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nData mais recente: {last_row['date'].strftime('%Y-%m-%d')}\")\n",
    "print(f\"Pre\u00e7o de fechamento: R$ {last_row['close']:.2f}\")\n",
    "print(f\"\\nRegime atual: Cluster {current_cluster} ({current_interp.upper()})\")\n",
    "print(f\"\\nProbabilidade de atingir {ga_config.target_return:.1%} em {ga_config.horizon} dias:\")\n",
    "print(f\"  -> {current_prob:.1f}%\")\n",
    "print(f\"\\nProbabilidade incondicional (m\u00e9dia hist\u00f3rica): {best_report['raw_probability_pct']:.1f}%\")\n",
    "\n",
    "# Compara\u00e7\u00e3o\n",
    "diff = current_prob - best_report['raw_probability_pct']\n",
    "if diff > 0:\n",
    "    print(f\"\\n\u2705 Regime atual tem probabilidade {diff:.1f} pontos percentuais ACIMA da m\u00e9dia\")\n",
    "else:\n",
    "    print(f\"\\n\u26a0\ufe0f Regime atual tem probabilidade {abs(diff):.1f} pontos percentuais ABAIXO da m\u00e9dia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<cell_type>markdown</cell_type>## Etapa 15: An\u00e1lise Dual - Fechar vs Tocar\n",
    "\n",
    "Comparamos duas probabilidades diferentes:\n",
    "- **P(fechar)**: Probabilidade do pre\u00e7o FECHAR acima do alvo em t+H\n",
    "- **P(tocar)**: Probabilidade do pre\u00e7o TOCAR o alvo em algum momento entre t+1 e t+H\n",
    "\n",
    "Esta an\u00e1lise \u00e9 \u00fatil para opera\u00e7\u00f5es de op\u00e7\u00f5es e stop-loss/take-profit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.calculators import FutureTouchCalculatorVectorized\n",
    "from src.analysis import DualProbabilityCalculator\n",
    "\n",
    "# Adicionar colunas de touch ao DataFrame com par\u00e2metros otimizados\n",
    "touch_calc = FutureTouchCalculatorVectorized(horizon=ga_config.horizon)\n",
    "df_dual = touch_calc.calculate(df_best)\n",
    "\n",
    "print(\"=== Novas Colunas de Touch ===\")\n",
    "print(f\"Colunas adicionadas: {touch_calc.output_columns}\")\n",
    "print(f\"\\nExemplo dos dados:\")\n",
    "print(df_dual[['date', 'close', f'log_return_future_{ga_config.horizon}', \n",
    "               f'log_return_touch_max_{ga_config.horizon}']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Criar calculador dual\ndual_calc = DualProbabilityCalculator(\n    close_return_column=f'log_return_future_{ga_config.horizon}',\n    touch_return_column=f'log_return_touch_max_{ga_config.horizon}',  # Para alvos de alta\n    target_return=ga_config.target_return,\n    regime_column='cluster',\n    horizon=ga_config.horizon\n)\n\n# Imprimir compara\u00e7\u00e3o formatada\ndual_calc.print_comparison(df_dual)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr\u00e1fico comparativo: P(fechar) vs P(tocar) por cluster\n",
    "dual_report = dual_calc.generate_report(df_dual)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "clusters_list = sorted(dual_report['conditional_probabilities'].keys())\n",
    "x = np.arange(len(clusters_list))\n",
    "width = 0.35\n",
    "\n",
    "close_probs = [dual_report['conditional_probabilities'][c]['prob_close'] * 100 for c in clusters_list]\n",
    "touch_probs = [dual_report['conditional_probabilities'][c]['prob_touch'] * 100 for c in clusters_list]\n",
    "\n",
    "bars1 = ax.bar(x - width/2, close_probs, width, label='P(fechar)', color='steelblue', alpha=0.8)\n",
    "bars2 = ax.bar(x + width/2, touch_probs, width, label='P(tocar)', color='coral', alpha=0.8)\n",
    "\n",
    "# Labels nos clusters\n",
    "cluster_labels = []\n",
    "for c in clusters_list:\n",
    "    interp = best_interp.get(int(float(c)), 'unknown')\n",
    "    cluster_labels.append(f\"Cluster {int(float(c))}\\n({interp})\")\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(cluster_labels)\n",
    "ax.set_ylabel('Probabilidade (%)')\n",
    "ax.set_title(f'Compara\u00e7\u00e3o: P(fechar) vs P(tocar) - Target: {ga_config.target_return:.1%} em {ga_config.horizon} dias')\n",
    "ax.legend()\n",
    "\n",
    "# Adicionar valores nas barras\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height, f'{height:.1f}%',\n",
    "            ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height, f'{height:.1f}%',\n",
    "            ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Ratio touch/close\n",
    "print(\"\\n=== Ratio Touch/Close por Cluster ===\")\n",
    "for c in clusters_list:\n",
    "    data = dual_report['conditional_probabilities'][c]\n",
    "    ratio = data['touch_vs_close_ratio']\n",
    "    interp = best_interp.get(int(float(c)), 'unknown')\n",
    "    print(f\"Cluster {int(float(c))} ({interp}): {ratio:.2f}x mais prov\u00e1vel tocar que fechar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Situa\u00e7\u00e3o atual com an\u00e1lise dual\n",
    "last_row = df_dual.iloc[-1]\n",
    "current_cluster = int(last_row['cluster'])\n",
    "current_interp = best_interp.get(current_cluster, 'unknown')\n",
    "\n",
    "current_data = dual_report['conditional_probabilities'][str(float(current_cluster))]\n",
    "current_prob_close = current_data['prob_close'] * 100\n",
    "current_prob_touch = current_data['prob_touch'] * 100\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SITUA\u00c7\u00c3O ATUAL - AN\u00c1LISE DUAL\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nData: {last_row['date'].strftime('%Y-%m-%d')}\")\n",
    "print(f\"Pre\u00e7o: R$ {last_row['close']:.2f}\")\n",
    "print(f\"Regime: Cluster {current_cluster} ({current_interp.upper()})\")\n",
    "\n",
    "print(f\"\\nProbabilidade de atingir {ga_config.target_return:.1%} em {ga_config.horizon} dias:\")\n",
    "print(f\"  P(fechar \u2265 alvo): {current_prob_close:.1f}%\")\n",
    "print(f\"  P(tocar o alvo):  {current_prob_touch:.1f}%\")\n",
    "print(f\"  Ratio:            {current_prob_touch/current_prob_close:.2f}x\")\n",
    "\n",
    "print(f\"\\n\ud83d\udcc8 Interpreta\u00e7\u00e3o:\")\n",
    "print(f\"  \u00c9 {current_prob_touch/current_prob_close:.1f}x mais prov\u00e1vel o pre\u00e7o TOCAR o alvo\")\n",
    "print(f\"  do que FECHAR acima dele.\")\n",
    "print(f\"\\n  Isso \u00e9 \u00fatil para:\")\n",
    "print(f\"  - Op\u00e7\u00f5es: P(tocar) relevante para barreiras knock-in/knock-out\")\n",
    "print(f\"  - Trading: P(tocar) para stop-loss e take-profit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 16: Salvando o Modelo para Produ\u00e7\u00e3o\n",
    "\n",
    "Usamos `RegimePredictor` para encapsular o modelo treinado e facilitar previs\u00f5es futuras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.prediction import RegimePredictor\n",
    "\n",
    "# Criar predictor a partir dos resultados do GA\n",
    "predictor = RegimePredictor(\n",
    "    chromosome=best,                      # Cromossomo otimizado\n",
    "    target_return=ga_config.target_return,\n",
    "    horizon=ga_config.horizon,\n",
    "    ticker=ticker,\n",
    "    data_dir=\"../data\"\n",
    ")\n",
    "\n",
    "# Treinar com os dados hist\u00f3ricos\n",
    "predictor.fit(df)\n",
    "\n",
    "# Salvar modelo para uso futuro\n",
    "predictor.save(\"../models/bova11_predictor\")\n",
    "print(\"\u2705 Modelo salvo em ../models/bova11_predictor.joblib e .json\")\n",
    "\n",
    "# Carregar modelo (simulando uso em produ\u00e7\u00e3o)\n",
    "predictor_loaded = RegimePredictor.load(\"../models/bova11_predictor\", data_dir=\"../data\")\n",
    "print(\"\u2705 Modelo carregado com sucesso!\")\n",
    "\n",
    "# Fazer previs\u00e3o do regime atual\n",
    "result = predictor_loaded.predict_current()\n",
    "\n",
    "# Exibir status formatado\n",
    "predictor_loaded.print_status(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 17: Otimiza\u00e7\u00e3o Multi-Alvo\n",
    "\n",
    "Para diferentes targets de retorno, o GA pode encontrar par\u00e2metros diferentes.\n",
    "O `MultiTargetOptimizer` roda GAs independentes para cada alvo e cria uma matriz de probabilidades.\n",
    "\n",
    "**NOTA**: Esta etapa \u00e9 MUITO intensiva computacionalmente. Use com cautela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de uso do MultiTargetOptimizer (N\u00c3O EXECUTAR - apenas demonstra\u00e7\u00e3o)\n",
    "# Este c\u00f3digo levaria MUITO tempo para rodar\n",
    "\n",
    "from config.search_space import TargetGrid\n",
    "from src.optimization import MultiTargetOptimizer\n",
    "from src.prediction import MultiTargetPredictor\n",
    "\n",
    "# Configurar grid de targets (1% a 5%, step 1%)\n",
    "target_grid = TargetGrid(\n",
    "    target_min=0.01,   # 1%\n",
    "    target_max=0.05,   # 5%\n",
    "    target_step=0.01   # 1%\n",
    ")\n",
    "\n",
    "print(\"=== Configura\u00e7\u00e3o Multi-Target ===\")\n",
    "print(f\"Targets: {target_grid.to_array()}\")\n",
    "print(f\"Total de GAs a executar: {len(target_grid)}\")\n",
    "\n",
    "# multi_ga_config j\u00e1 definido na c\u00e9lula de configura\u00e7\u00e3o centralizada\n",
    "print(f\"\\nUsando multi_ga_config da c\u00e9lula centralizada:\")\n",
    "print(f\"  Popula\u00e7\u00e3o: {multi_ga_config.population_size}\")\n",
    "print(f\"  Gera\u00e7\u00f5es: {multi_ga_config.generations}\")\n",
    "print(f\"  Early Stopping: {multi_ga_config.early_stopping}\")\n",
    "\n",
    "# DESCOMENTE PARA EXECUTAR (demora!)\n",
    "# optimizer = MultiTargetOptimizer(\n",
    "#     df=df,\n",
    "#     horizon=HORIZON,\n",
    "#     target_grid=target_grid,\n",
    "#     ga_config=multi_ga_config\n",
    "# )\n",
    "# \n",
    "# results = optimizer.run(verbose=True)\n",
    "# results.save(\"../models/multi_target_h2\")\n",
    "# \n",
    "# # Criar predictor\n",
    "# multi_predictor = MultiTargetPredictor.from_optimization(results, df)\n",
    "# multi_predictor.save(\"../models/multi_target_h2_predictor\")\n",
    "# \n",
    "# # Ver matriz de probabilidades\n",
    "# matrix = multi_predictor.predict_current(ticker)\n",
    "# multi_predictor.print_matrix(ticker)\n",
    "\n",
    "print(\"\\n\u26a0\ufe0f C\u00f3digo comentado para evitar execu\u00e7\u00e3o longa.\")\n",
    "print(\"Descomente as linhas acima para executar a otimiza\u00e7\u00e3o multi-alvo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 18: Grade de Strikes para Op\u00e7\u00f5es\n",
    "\n",
    "O `StrikeGridOptimizer` \u00e9 similar ao MultiTargetOptimizer, mas trabalha com pre\u00e7os absolutos (strikes).\n",
    "Ideal para precifica\u00e7\u00e3o de op\u00e7\u00f5es.\n",
    "\n",
    "**Fluxo:**\n",
    "1. Define strikes (ex: R$ 120, 125, 130...)\n",
    "2. Converte cada strike para target return: `(strike / pre\u00e7o_atual) - 1`\n",
    "3. Roda GA para cada target exato\n",
    "4. Gera matriz de probabilidades por strike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Exemplo de uso do StrikeGridOptimizer com Progress Callback\n\nfrom src.optimization import StrikeGridOptimizer\nfrom src.optimization.progress_callback import SimpleProgressCallback\nfrom src.prediction import StrikeGridPredictor\n\n# Pre\u00e7o atual do ativo\ncurrent_price = df['close'].iloc[-1]\nprint(f\"Pre\u00e7o atual: R$ {current_price:.2f}\")\n\n# Definir strikes (exemplo para BOVA11)\nstrikes = list(range(int(current_price * 0.95), int(current_price * 1.10), 1))  # -5% a +10%, step de R$ 1\nprint(f\"\\nStrikes definidos: {strikes}\")\nprint(f\"Total de GAs a executar: {len(strikes)}\")\n\n# Preview da convers\u00e3o strike \u2192 target\nprint(\"\\n=== Preview Strike \u2192 Target ===\")\nprint(f\"{'Strike':<12} {'Retorno':<12} {'Dire\u00e7\u00e3o':<10}\")\nprint(\"-\" * 34)\nfor strike in strikes[:5]:\n    target_return = (strike / current_price) - 1\n    direction = 'UP' if target_return > 0 else 'DOWN' if target_return < 0 else 'ATM'\n    print(f\"R$ {strike:<9.2f} {target_return*100:+.2f}%       {direction:<10}\")\nif len(strikes) > 5:\n    print(f\"... ({len(strikes) - 5} mais)\")\n\n# Usando multi_ga_config da c\u00e9lula de configura\u00e7\u00e3o centralizada\nprint(f\"\\nUsando multi_ga_config da c\u00e9lula centralizada:\")\nprint(f\"  Popula\u00e7\u00e3o: {multi_ga_config.population_size}\")\nprint(f\"  Gera\u00e7\u00f5es: {multi_ga_config.generations}\")\nprint(f\"  Early Stopping: {multi_ga_config.early_stopping}\")\n\n# Factory para criar callback de progresso para cada GA\ndef create_ga_callback(strike_idx, strike):\n    return SimpleProgressCallback(\n        total_generations=multi_ga_config.generations,\n        print_every=5  # Atualiza a cada 5 gera\u00e7\u00f5es\n    )\n\n# Executar otimiza\u00e7\u00e3o\nstrike_optimizer = StrikeGridOptimizer(\n    df=df,\n    current_price=current_price,\n    strikes=strikes,\n    horizon=HORIZON,\n    ga_config=multi_ga_config\n)\n\nprint(f\"\\n\u23f3 Iniciando otimiza\u00e7\u00e3o para {len(strikes)} strikes...\")\n\nstrike_results = strike_optimizer.run(\n    verbose=True,\n    ga_progress_callback_factory=create_ga_callback,\n    parallel_ga=False  # Melhor para Jupyter notebooks\n)\n\n# Salvar resultados\nstrike_results.save(\"../models/strike_grid_h2\")\n\n# Criar predictor\nstrike_predictor = StrikeGridPredictor.from_optimization(strike_results, df)\nstrike_predictor.save(\"../models/strike_grid_h2_predictor\")\n\n# Ver matriz de strikes\nstrike_predictor.print_matrix(ticker)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclus\u00e3o\n",
    "\n",
    "Este notebook demonstrou o fluxo completo do sistema QuantNote:\n",
    "\n",
    "1. **Configura\u00e7\u00e3o** com valida\u00e7\u00e3o via Pydantic\n",
    "2. **Obten\u00e7\u00e3o de dados** do Yahoo Finance com rate limiting\n",
    "3. **Valida\u00e7\u00e3o** de dados com m\u00faltiplos validators\n",
    "4. **Pipeline de calculadores** com resolu\u00e7\u00e3o autom\u00e1tica de depend\u00eancias\n",
    "5. **Classifica\u00e7\u00e3o de regimes** (manual e K-Means)\n",
    "6. **C\u00e1lculo de probabilidades** condicionais\n",
    "7. **Visualiza\u00e7\u00e3o** de distribui\u00e7\u00f5es\n",
    "8. **Walk-forward validation** para evitar overfitting\n",
    "9. **Otimiza\u00e7\u00e3o** com algoritmo gen\u00e9tico\n",
    "10. **An\u00e1lise dual** - P(fechar) vs P(tocar)\n",
    "\n",
    "### M\u00e9tricas de Probabilidade\n",
    "\n",
    "- **P(fechar)**: Probabilidade de fechar acima do alvo no final do per\u00edodo\n",
    "- **P(tocar)**: Probabilidade de atingir o alvo em algum momento durante o per\u00edodo\n",
    "\n",
    "### Pr\u00f3ximos Passos\n",
    "\n",
    "- Testar com outros ativos\n",
    "- Ajustar par\u00e2metros do GA para busca mais ampla\n",
    "- Implementar novos indicadores (RSI, MACD, etc.)\n",
    "- Integrar com sistema de backtesting\n",
    "- Usar P(tocar) para otimiza\u00e7\u00e3o de op\u00e7\u00f5es"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}