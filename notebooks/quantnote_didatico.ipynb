{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QuantNote - Tutorial DidÃ¡tico\n",
    "\n",
    "## Sistema Quantitativo para Probabilidades de Retorno Condicionadas por Regime\n",
    "\n",
    "Este notebook demonstra passo a passo o funcionamento do sistema QuantNote.\n",
    "\n",
    "### Objetivo\n",
    "Calcular a probabilidade de um ativo atingir um retorno alvo em H perÃ­odos, condicionada ao regime de mercado atual.\n",
    "\n",
    "### Conceitos Principais\n",
    "1. **Log-Retornos**: Usamos log(P_t/P_{t-1}) pois sÃ£o aditivos e simÃ©tricos\n",
    "2. **Slope (InclinaÃ§Ã£o)**: TendÃªncia calculada via regressÃ£o linear do log-preÃ§o\n",
    "3. **Volatilidade**: Desvio padrÃ£o dos retornos em janela mÃ³vel\n",
    "4. **Regimes**: Estados do mercado (bull/bear/flat combinados com alta/baixa volatilidade)\n",
    "5. **K-Means**: Clustering para detectar regimes automaticamente\n",
    "6. **Walk-Forward**: ValidaÃ§Ã£o para evitar overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 1: Setup e Imports\n",
    "\n",
    "Primeiro, configuramos o ambiente e importamos os mÃ³dulos necessÃ¡rios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup do path para imports\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "\n",
    "# Imports padrÃ£o\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Verificar se os imports funcionam\n",
    "print(\"Python path configurado!\")\n",
    "print(f\"DiretÃ³rio de trabalho: {os.getcwd()}\")\n",
    "\n",
    "# ConfiguraÃ§Ã£o de visualizaÃ§Ã£o\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.width', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 2: ConfiguraÃ§Ã£o do Sistema\n",
    "\n",
    "O sistema usa Pydantic para validar configuraÃ§Ãµes. Isso garante que parÃ¢metros invÃ¡lidos sejam rejeitados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.settings import AnalysisConfig, InfrastructureConfig, Config\n",
    "from config.search_space import GAConfig, GASearchSpace\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURAÃ‡ÃƒO CENTRALIZADA\n",
    "# =============================================================================\n",
    "# Altere os parÃ¢metros abaixo conforme necessÃ¡rio.\n",
    "# Todos os notebooks usarÃ£o estas configuraÃ§Ãµes.\n",
    "\n",
    "# --- Ticker a analisar ---\n",
    "TICKER = \"BOVA11.SA\"\n",
    "\n",
    "# --- ParÃ¢metros de PrediÃ§Ã£o (usados pelo GA) ---\n",
    "TARGET_RETURN = 0.03   # Target: 3% de variaÃ§Ã£o\n",
    "HORIZON = 7            # Horizonte: 7 dias\n",
    "\n",
    "# --- Indicadores Ativos ---\n",
    "# Controla quais indicadores sÃ£o usados em TODO o notebook:\n",
    "# - Pipeline de calculadores\n",
    "# - EspaÃ§o de busca do GA (parÃ¢metros do indicador)\n",
    "# - Features do K-Means\n",
    "# - Features do Explainer (Decision Tree / Random Forest)\n",
    "#\n",
    "# True  = Indicador sempre ativo (GA otimiza os parÃ¢metros)\n",
    "# False = Indicador desabilitado (nÃ£o entra no pipeline/GA/K-Means/Explainer)\n",
    "USE_VOLATILITY = False        # Volatilidade (desvio padrÃ£o dos retornos)\n",
    "USE_ROLLING_RETURN = False    # Retorno acumulado em janela\n",
    "USE_MA_DISTANCE = True       # DistÃ¢ncia entre MAs (rÃ¡pida - lenta)\n",
    "USE_TREND_INDICATOR = False   # Trend Indicator (higher lows / lower highs)\n",
    "\n",
    "# --- ParÃ¢metros do GA Principal ---\n",
    "GA_POPULATION_SIZE = 100\n",
    "GA_GENERATIONS = 1000\n",
    "GA_N_FOLDS = 3\n",
    "GA_EARLY_STOPPING = True\n",
    "\n",
    "# --- ParÃ¢metros do GA para Multi-Target/Strike Grid (reduzido para demo) ---\n",
    "MULTI_GA_POPULATION_SIZE = 50\n",
    "MULTI_GA_GENERATIONS = 100\n",
    "\n",
    "# --- ParÃ¢metros de AnÃ¡lise ExploratÃ³ria (Etapas 1-11) ---\n",
    "ANALYSIS_WINDOW_SLOPE = 20\n",
    "ANALYSIS_WINDOW_VOLATILITY = 20\n",
    "ANALYSIS_WINDOW_ROLLING_RETURN = 20\n",
    "ANALYSIS_WINDOW_TREND_INDICATOR = 10\n",
    "ANALYSIS_TREND_SLOPE_MULTIPLIER = 2.0  # Janela do slope = window * multiplier\n",
    "ANALYSIS_N_CLUSTERS = 6\n",
    "ANALYSIS_TARGET_RETURN = 0.05  # 5% para exploraÃ§Ã£o didÃ¡tica\n",
    "\n",
    "# --- ParÃ¢metros de MÃ©dias MÃ³veis ---\n",
    "MA_FAST_PERIOD = 9     # MÃ©dia mÃ³vel rÃ¡pida\n",
    "MA_SLOW_PERIOD = 21    # MÃ©dia mÃ³vel lenta\n",
    "\n",
    "# =============================================================================\n",
    "# Criar objetos de configuraÃ§Ã£o\n",
    "# =============================================================================\n",
    "\n",
    "# Config para anÃ¡lise exploratÃ³ria (etapas iniciais do notebook)\n",
    "config = Config()\n",
    "config.analysis.future_return_periods = HORIZON\n",
    "config.analysis.window_slope = ANALYSIS_WINDOW_SLOPE\n",
    "config.analysis.window_volatility = ANALYSIS_WINDOW_VOLATILITY\n",
    "config.analysis.window_rolling_return = ANALYSIS_WINDOW_ROLLING_RETURN\n",
    "config.analysis.window_trend_indicator = ANALYSIS_WINDOW_TREND_INDICATOR\n",
    "config.analysis.trend_slope_multiplier = ANALYSIS_TREND_SLOPE_MULTIPLIER\n",
    "config.analysis.n_clusters = ANALYSIS_N_CLUSTERS\n",
    "config.analysis.target_return = ANALYSIS_TARGET_RETURN\n",
    "config.analysis.ma_fast_period = MA_FAST_PERIOD\n",
    "config.analysis.ma_slow_period = MA_SLOW_PERIOD\n",
    "\n",
    "# Configurar indicadores ativos\n",
    "config.analysis.use_volatility = USE_VOLATILITY\n",
    "config.analysis.use_rolling_return = USE_ROLLING_RETURN\n",
    "config.analysis.use_ma_distance = USE_MA_DISTANCE\n",
    "config.analysis.use_trend_indicator = USE_TREND_INDICATOR\n",
    "\n",
    "# Config do GA para otimizaÃ§Ã£o principal\n",
    "# Os flags force_use_* controlam se o indicador Ã© forÃ§ado a True, False, ou None (GA decide)\n",
    "# Quando USE_* = True, forÃ§amos True para sempre usar\n",
    "# Quando USE_* = False, forÃ§amos False para nunca usar\n",
    "ga_config = GAConfig(\n",
    "    target_return=TARGET_RETURN,\n",
    "    horizon=HORIZON,\n",
    "    population_size=GA_POPULATION_SIZE,\n",
    "    generations=GA_GENERATIONS,\n",
    "    n_folds=GA_N_FOLDS,\n",
    "    stability_penalty=0.1,\n",
    "    elite_size=2,\n",
    "    early_stopping=GA_EARLY_STOPPING,\n",
    "    # ForÃ§ar indicadores conforme configuraÃ§Ã£o global\n",
    "    force_use_volatility=USE_VOLATILITY,\n",
    "    force_use_rolling_return=USE_ROLLING_RETURN,\n",
    "    force_use_ma_distance=USE_MA_DISTANCE,\n",
    "    force_use_trend_indicator=USE_TREND_INDICATOR,\n",
    ")\n",
    "\n",
    "# Config do GA para multi-target e strike grid (reduzido)\n",
    "multi_ga_config = GAConfig(\n",
    "    target_return=TARGET_RETURN,  # SerÃ¡ sobrescrito pelo optimizer\n",
    "    horizon=HORIZON,\n",
    "    population_size=MULTI_GA_POPULATION_SIZE,\n",
    "    generations=MULTI_GA_GENERATIONS,\n",
    "    n_folds=GA_N_FOLDS,\n",
    "    early_stopping=GA_EARLY_STOPPING,\n",
    "    # ForÃ§ar indicadores conforme configuraÃ§Ã£o global\n",
    "    force_use_volatility=USE_VOLATILITY,\n",
    "    force_use_rolling_return=USE_ROLLING_RETURN,\n",
    "    force_use_ma_distance=USE_MA_DISTANCE,\n",
    "    force_use_trend_indicator=USE_TREND_INDICATOR,\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# Exibir configuraÃ§Ãµes\n",
    "# =============================================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"CONFIGURAÃ‡ÃƒO CENTRALIZADA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nðŸ“Š TICKER: {TICKER}\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ ParÃ¢metros de PrediÃ§Ã£o:\")\n",
    "print(f\"   Target Return: {TARGET_RETURN:.1%}\")\n",
    "print(f\"   Horizonte: {HORIZON} dias\")\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Indicadores Ativos:\")\n",
    "print(f\"   {'âœ…' if USE_VOLATILITY else 'âŒ'} Volatility\")\n",
    "print(f\"   {'âœ…' if USE_ROLLING_RETURN else 'âŒ'} Rolling Return\")\n",
    "print(f\"   {'âœ…' if USE_MA_DISTANCE else 'âŒ'} MA Distance\")\n",
    "print(f\"   {'âœ…' if USE_TREND_INDICATOR else 'âŒ'} Trend Indicator\")\n",
    "active_count = sum([USE_VOLATILITY, USE_ROLLING_RETURN, USE_MA_DISTANCE, USE_TREND_INDICATOR])\n",
    "print(f\"   Total: {active_count + 1} features (slope Ã© sempre incluÃ­do)\")\n",
    "\n",
    "print(f\"\\nðŸ§¬ GA Principal:\")\n",
    "print(f\"   PopulaÃ§Ã£o: {GA_POPULATION_SIZE}\")\n",
    "print(f\"   GeraÃ§Ãµes: {GA_GENERATIONS}\")\n",
    "print(f\"   Folds: {GA_N_FOLDS}\")\n",
    "print(f\"   Early Stopping: {GA_EARLY_STOPPING}\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ GA Multi-Target/Strike Grid:\")\n",
    "print(f\"   PopulaÃ§Ã£o: {MULTI_GA_POPULATION_SIZE}\")\n",
    "print(f\"   GeraÃ§Ãµes: {MULTI_GA_GENERATIONS}\")\n",
    "\n",
    "print(f\"\\nðŸ“ˆ AnÃ¡lise ExploratÃ³ria:\")\n",
    "print(f\"   Window Slope: {ANALYSIS_WINDOW_SLOPE}\")\n",
    "if USE_VOLATILITY:\n",
    "    print(f\"   Window Volatility: {ANALYSIS_WINDOW_VOLATILITY}\")\n",
    "if USE_ROLLING_RETURN:\n",
    "    print(f\"   Window Rolling Return: {ANALYSIS_WINDOW_ROLLING_RETURN}\")\n",
    "if USE_TREND_INDICATOR:\n",
    "    print(f\"   Window Trend Indicator: {ANALYSIS_WINDOW_TREND_INDICATOR}\")\n",
    "    print(f\"   Trend Slope Multiplier: {ANALYSIS_TREND_SLOPE_MULTIPLIER}\")\n",
    "print(f\"   Clusters: {ANALYSIS_N_CLUSTERS}\")\n",
    "print(f\"   Target (exploratÃ³rio): {ANALYSIS_TARGET_RETURN:.1%}\")\n",
    "\n",
    "if USE_MA_DISTANCE:\n",
    "    print(f\"\\nðŸ“‰ MÃ©dias MÃ³veis:\")\n",
    "    print(f\"   MA RÃ¡pida: {MA_FAST_PERIOD} perÃ­odos\")\n",
    "    print(f\"   MA Lenta: {MA_SLOW_PERIOD} perÃ­odos\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 3: ObtenÃ§Ã£o de Dados\n",
    "\n",
    "Usamos `YahooDataSource` para baixar dados OHLCV. O sistema tem rate limiting para evitar bloqueio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.infrastructure.yahoo_data_source import YahooDataSource\n",
    "from src.infrastructure.parquet_repository import ParquetRepository\n",
    "from src.infrastructure.file_logger import FileLogger, NullLogger\n",
    "\n",
    "# Criar logger (usar NullLogger para menos output)\n",
    "logger = NullLogger()  # ou FileLogger(\"quantnote\") para logs detalhados\n",
    "\n",
    "# Data source e repository\n",
    "data_source = YahooDataSource(calls_per_minute=5, logger=logger)\n",
    "repository = ParquetRepository(data_dir=\"../data\", logger=logger)\n",
    "\n",
    "# Usar ticker da configuraÃ§Ã£o centralizada\n",
    "ticker = TICKER\n",
    "\n",
    "print(f\"Buscando dados para {ticker}...\")\n",
    "\n",
    "# Verificar se dados no cache estÃ£o atualizados\n",
    "is_current, last_date = repository.is_data_current(ticker, max_age_days=1)\n",
    "\n",
    "if is_current:\n",
    "    print(f\"âœ… Cache atualizado (Ãºltima data: {last_date.date()})\")\n",
    "    df = repository.load(ticker)\n",
    "else:\n",
    "    if last_date:\n",
    "        print(f\"âš ï¸  Cache desatualizado (Ãºltima data: {last_date.date()})\")\n",
    "    else:\n",
    "        print(\"ðŸ“¥ Dados nÃ£o encontrados no cache.\")\n",
    "    \n",
    "    print(\"Baixando dados atualizados do Yahoo Finance...\")\n",
    "    df = data_source.fetch_ohlcv(ticker)\n",
    "    \n",
    "    # Limpar arquivos antigos e salvar novos dados\n",
    "    deleted = repository.delete_old_files(ticker, keep_latest=0)\n",
    "    if deleted:\n",
    "        print(f\"ðŸ—‘ï¸  {deleted} arquivo(s) antigo(s) removido(s)\")\n",
    "    \n",
    "    repository.save(df, ticker)\n",
    "    print(\"âœ… Dados atualizados salvos no cache.\")\n",
    "\n",
    "print(f\"\\n=== Dados Obtidos ===\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"PerÃ­odo: {df['date'].min().date()} a {df['date'].max().date()}\")\n",
    "print(f\"\\nPrimeiras linhas:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 4: ValidaÃ§Ã£o de Dados\n",
    "\n",
    "Antes de processar, validamos os dados para garantir qualidade.\n",
    "\n",
    "O sistema usa o padrÃ£o **Composite** para combinar mÃºltiplos validadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.infrastructure.validators import create_default_validator\n",
    "\n",
    "# Criar validador composto\n",
    "validator = create_default_validator(\n",
    "    min_length=config.analysis.min_data_points,\n",
    "    max_window=max(\n",
    "        config.analysis.window_slope, \n",
    "        config.analysis.window_volatility,\n",
    "        config.analysis.window_trend_indicator\n",
    "    )\n",
    ")\n",
    "\n",
    "# Executar validaÃ§Ã£o\n",
    "validation = validator.validate(df)\n",
    "\n",
    "print(\"=== Resultado da ValidaÃ§Ã£o ===\")\n",
    "print(f\"VÃ¡lido: {'SIM' if validation.is_valid else 'NÃƒO'}\")\n",
    "\n",
    "if validation.errors:\n",
    "    print(f\"\\nERROS:\")\n",
    "    for error in validation.errors:\n",
    "        print(f\"  - {error}\")\n",
    "\n",
    "if validation.warnings:\n",
    "    print(f\"\\nAVISOS:\")\n",
    "    for warning in validation.warnings:\n",
    "        print(f\"  - {warning}\")\n",
    "\n",
    "if validation.is_valid and not validation.warnings:\n",
    "    print(\"Todos os testes passaram sem avisos!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 5: Calculadores Individuais\n",
    "\n",
    "Vamos explorar cada calculador individualmente para entender o que faz.\n",
    "\n",
    "Cada calculador implementa `IColumnCalculator` e segue o princÃ­pio de **Single Responsibility**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.calculators.log_price_calculator import LogPriceCalculator\n",
    "\n",
    "# 5.1 - Log Price Calculator\n",
    "log_price_calc = LogPriceCalculator()\n",
    "\n",
    "print(\"=== LogPriceCalculator ===\")\n",
    "print(f\"Nome: {log_price_calc.name}\")\n",
    "print(f\"Colunas requeridas: {log_price_calc.required_columns}\")\n",
    "print(f\"Colunas produzidas: {log_price_calc.output_columns}\")\n",
    "\n",
    "# Aplicar\n",
    "df_step1 = log_price_calc.calculate(df)\n",
    "\n",
    "# Visualizar resultado\n",
    "print(f\"\\nFormula: log_close = ln(close)\")\n",
    "print(f\"\\nExemplo:\")\n",
    "print(df_step1[['date', 'close', 'log_close']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.calculators.log_return_calculator import LogReturnCalculator\n",
    "\n",
    "# 5.2 - Log Return Calculator\n",
    "log_return_calc = LogReturnCalculator(window=config.analysis.window_rolling_return)\n",
    "\n",
    "print(\"=== LogReturnCalculator ===\")\n",
    "print(f\"Nome: {log_return_calc.name}\")\n",
    "print(f\"Colunas requeridas: {log_return_calc.required_columns}\")\n",
    "print(f\"Colunas produzidas: {log_return_calc.output_columns}\")\n",
    "\n",
    "# Aplicar\n",
    "df_step2 = log_return_calc.calculate(df_step1)\n",
    "\n",
    "print(f\"\\nFormulas:\")\n",
    "print(f\"  log_return = ln(close_t / close_{{t-1}})\")\n",
    "print(f\"  log_return_rolling_20 = sum(log_return over 20 days)\")\n",
    "print(f\"\\nExemplo:\")\n",
    "print(df_step2[['date', 'close', 'log_return', f'log_return_rolling_{config.analysis.window_rolling_return}']].head(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.calculators.volatility_calculator import VolatilityCalculator\n",
    "\n",
    "# 5.3 - Volatility Calculator\n",
    "vol_calc = VolatilityCalculator(window=config.analysis.window_volatility)\n",
    "\n",
    "print(\"=== VolatilityCalculator ===\")\n",
    "print(f\"Nome: {vol_calc.name}\")\n",
    "print(f\"Colunas requeridas: {vol_calc.required_columns}\")\n",
    "print(f\"Colunas produzidas: {vol_calc.output_columns}\")\n",
    "\n",
    "# Aplicar\n",
    "df_step3 = vol_calc.calculate(df_step2)\n",
    "\n",
    "print(f\"\\nFormula: volatility = std(log_return over {config.analysis.window_volatility} days)\")\n",
    "print(f\"\\nExemplo:\")\n",
    "print(df_step3[['date', 'log_return', f'volatility_{config.analysis.window_volatility}']].tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.calculators.slope_calculator import SlopeCalculator\n",
    "\n",
    "# 5.4 - Slope Calculator\n",
    "slope_calc = SlopeCalculator(window=config.analysis.window_slope)\n",
    "\n",
    "print(\"=== SlopeCalculator ===\")\n",
    "print(f\"Nome: {slope_calc.name}\")\n",
    "print(f\"Colunas requeridas: {slope_calc.required_columns}\")\n",
    "print(f\"Colunas produzidas: {slope_calc.output_columns}\")\n",
    "\n",
    "# Aplicar\n",
    "df_step4 = slope_calc.calculate(df_step3)\n",
    "\n",
    "print(f\"\\nFormula: slope = coef angular da regressÃ£o linear de log_close sobre {config.analysis.window_slope} dias\")\n",
    "print(f\"\\nInterpretaÃ§Ã£o:\")\n",
    "print(f\"  slope > 0: tendÃªncia de alta\")\n",
    "print(f\"  slope < 0: tendÃªncia de baixa\")\n",
    "print(f\"  slope â‰ˆ 0: mercado lateral\")\n",
    "print(f\"\\nExemplo:\")\n",
    "print(df_step4[['date', 'log_close', f'slope_{config.analysis.window_slope}']].tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.calculators.ma_distance_calculator import MADistanceCalculator\n",
    "\n",
    "# 5.5 - MA Distance Calculator\n",
    "ma_dist_calc = MADistanceCalculator(\n",
    "    fast_period=config.analysis.ma_fast_period,\n",
    "    slow_period=config.analysis.ma_slow_period\n",
    ")\n",
    "\n",
    "print(\"=== MADistanceCalculator ===\")\n",
    "print(f\"Nome: {ma_dist_calc.name}\")\n",
    "print(f\"Colunas requeridas: {ma_dist_calc.required_columns}\")\n",
    "print(f\"Colunas produzidas: {ma_dist_calc.output_columns}\")\n",
    "\n",
    "# Aplicar\n",
    "df_step4b = ma_dist_calc.calculate(df_step4)\n",
    "\n",
    "ma_col = f'ma_dist_{config.analysis.ma_fast_period}_{config.analysis.ma_slow_period}'\n",
    "\n",
    "print(f\"\\nFormula:\")\n",
    "print(f\"  MA_fast = SMA(close, {config.analysis.ma_fast_period})\")\n",
    "print(f\"  MA_slow = SMA(close, {config.analysis.ma_slow_period})\")\n",
    "print(f\"  distance = MA_fast - MA_slow\")\n",
    "print(f\"  {ma_col} = normalize(distance, min=-1, max=1)\")\n",
    "\n",
    "print(f\"\\nInterpretaÃ§Ã£o:\")\n",
    "print(f\"  > 0: tendÃªncia de alta (MA rÃ¡pida > MA lenta)\")\n",
    "print(f\"  < 0: tendÃªncia de baixa (MA rÃ¡pida < MA lenta)\")\n",
    "print(f\"  â‰ˆ 0: mÃ©dias cruzando/convergindo\")\n",
    "\n",
    "print(f\"\\nExemplo:\")\n",
    "print(df_step4b[['date', 'close', ma_col]].tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.calculators.trend_indicator_calculator import TrendIndicatorCalculator\n",
    "\n",
    "# 5.5b - Trend Indicator Calculator\n",
    "# Indicador de tendÃªncia baseado em Higher Lows e Lower Highs, filtrado pela direÃ§Ã£o do slope\n",
    "trend_calc = TrendIndicatorCalculator(\n",
    "    window=config.analysis.window_trend_indicator,\n",
    "    slope_multiplier=config.analysis.trend_slope_multiplier\n",
    ")\n",
    "\n",
    "print(\"=== TrendIndicatorCalculator ===\")\n",
    "print(f\"Nome: {trend_calc.name}\")\n",
    "print(f\"Colunas requeridas: {trend_calc.required_columns}\")\n",
    "print(f\"Colunas produzidas: {trend_calc.output_columns}\")\n",
    "\n",
    "# Aplicar\n",
    "df_step4c = trend_calc.calculate(df_step4b)\n",
    "\n",
    "window = config.analysis.window_trend_indicator\n",
    "slope_window = int(window * config.analysis.trend_slope_multiplier)\n",
    "\n",
    "print(f\"\\n=== LÃ³gica ===\")\n",
    "print(f\"1. Calcula slope em janela de {slope_window} dias (window * multiplier)\")\n",
    "print(f\"2. Se slope > 0 (uptrend): conta higher_lows na janela de {window} dias â†’ valor POSITIVO\")\n",
    "print(f\"3. Se slope <= 0 (downtrend): conta lower_highs na janela de {window} dias â†’ valor NEGATIVO\")\n",
    "\n",
    "print(f\"\\n=== Colunas de SaÃ­da ===\")\n",
    "print(f\"- trend_indicator_{window}: Valor COM sinal (+higher_lows ou -lower_highs)\")\n",
    "print(f\"- trend_indicator_norm_{window}: Normalizado entre -1 e +1\")\n",
    "print(f\"- trend_strength_{window}: Valor absoluto (forÃ§a sem direÃ§Ã£o)\")\n",
    "print(f\"- trend_strength_norm_{window}: ForÃ§a normalizada entre 0 e 1\")\n",
    "\n",
    "print(f\"\\n=== Uso ===\")\n",
    "print(f\"- Para visualizaÃ§Ã£o/interpretaÃ§Ã£o: use trend_indicator (com sinal)\")\n",
    "print(f\"- Para K-Means clustering: use trend_strength (abs) para evitar redundÃ¢ncia com slope\")\n",
    "print(f\"  (O sinal jÃ¡ estÃ¡ capturado pelo slope, entÃ£o usamos apenas a magnitude)\")\n",
    "\n",
    "print(f\"\\n=== Amostra (valores com sinal) ===\")\n",
    "trend_cols = [f'trend_indicator_{window}', f'trend_indicator_norm_{window}']\n",
    "print(df_step4c[['date', 'high', 'low'] + trend_cols].dropna().tail(10))\n",
    "\n",
    "print(f\"\\n=== Amostra (forÃ§a absoluta - usada no K-Means) ===\")\n",
    "strength_cols = [f'trend_strength_{window}', f'trend_strength_norm_{window}']\n",
    "print(df_step4c[['date'] + strength_cols].dropna().tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.calculators.future_return_calculator import FutureReturnCalculator\n",
    "\n",
    "# 5.6 - Future Return Calculator\n",
    "future_calc = FutureReturnCalculator(horizon=config.analysis.future_return_periods)\n",
    "\n",
    "print(\"=== FutureReturnCalculator ===\")\n",
    "print(f\"Nome: {future_calc.name}\")\n",
    "print(f\"Colunas requeridas: {future_calc.required_columns}\")\n",
    "print(f\"Colunas produzidas: {future_calc.output_columns}\")\n",
    "\n",
    "# Aplicar\n",
    "df_step5 = future_calc.calculate(df_step4)\n",
    "\n",
    "print(f\"\\nFormula: log_return_future_{config.analysis.future_return_periods} = ln(close_{{t+{config.analysis.future_return_periods}}} / close_t)\")\n",
    "print(f\"\\nNOTA: Esta coluna Ã© a variÃ¡vel TARGET que queremos prever!\")\n",
    "print(f\"\\nExemplo:\")\n",
    "print(df_step5[['date', 'close', f'log_return_future_{config.analysis.future_return_periods}']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 6: Pipeline com ResoluÃ§Ã£o AutomÃ¡tica de DependÃªncias\n",
    "\n",
    "O `CalculatorPipeline` usa **topological sort** para ordenar os calculadores automaticamente.\n",
    "\n",
    "Isso implementa o princÃ­pio **Open/Closed** - podemos adicionar calculadores sem modificar o pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.calculators.pipeline import CalculatorPipeline\n",
    "from src.calculators.log_price_calculator import LogPriceCalculator\n",
    "from src.calculators.log_return_calculator import LogReturnCalculator\n",
    "from src.calculators.future_return_calculator import FutureReturnCalculator\n",
    "from src.calculators.volatility_calculator import VolatilityCalculator\n",
    "from src.calculators.slope_calculator import SlopeCalculator\n",
    "from src.calculators.ma_distance_calculator import MADistanceCalculator\n",
    "from src.calculators.trend_indicator_calculator import TrendIndicatorCalculator\n",
    "\n",
    "# Criar lista de calculadores baseada nos indicadores ativos (da cÃ©lula de configuraÃ§Ã£o)\n",
    "calculators = [\n",
    "    LogPriceCalculator(),                                       # Sempre incluÃ­do\n",
    "    LogReturnCalculator(window=config.analysis.window_rolling_return),  # Sempre incluÃ­do (rolling return Ã© opcional)\n",
    "    SlopeCalculator(window=config.analysis.window_slope),       # Sempre incluÃ­do (base para clustering)\n",
    "    FutureReturnCalculator(horizon=config.analysis.future_return_periods),  # Sempre incluÃ­do (target)\n",
    "]\n",
    "\n",
    "# Adicionar indicadores opcionais conforme configuraÃ§Ã£o\n",
    "if USE_VOLATILITY:\n",
    "    calculators.append(VolatilityCalculator(window=config.analysis.window_volatility))\n",
    "\n",
    "if USE_MA_DISTANCE:\n",
    "    calculators.append(MADistanceCalculator(\n",
    "        fast_period=config.analysis.ma_fast_period,\n",
    "        slow_period=config.analysis.ma_slow_period\n",
    "    ))\n",
    "\n",
    "if USE_TREND_INDICATOR:\n",
    "    calculators.append(TrendIndicatorCalculator(\n",
    "        window=config.analysis.window_trend_indicator,\n",
    "        slope_multiplier=config.analysis.trend_slope_multiplier\n",
    "    ))\n",
    "\n",
    "# Criar pipeline (note que a ordem nÃ£o importa - serÃ¡ resolvida automaticamente)\n",
    "pipeline = CalculatorPipeline(calculators, logger=logger)\n",
    "\n",
    "# Executar pipeline\n",
    "df_analysis = pipeline.run(df)\n",
    "\n",
    "print(\"=== Pipeline Executado ===\")\n",
    "print(f\"Ordem de execuÃ§Ã£o: {pipeline.get_execution_order()}\")\n",
    "print(f\"\\nColunas originais: {len(df.columns)}\")\n",
    "print(f\"Colunas apÃ³s pipeline: {len(df_analysis.columns)}\")\n",
    "print(f\"\\nNovas colunas: {list(pipeline.get_all_output_columns())}\")\n",
    "\n",
    "# Mostrar indicadores incluÃ­dos\n",
    "print(f\"\\n=== Indicadores IncluÃ­dos ===\")\n",
    "print(f\"  âœ… Slope (sempre incluÃ­do)\")\n",
    "if USE_VOLATILITY:\n",
    "    print(f\"  âœ… Volatility\")\n",
    "else:\n",
    "    print(f\"  âŒ Volatility (desabilitado)\")\n",
    "if USE_ROLLING_RETURN:\n",
    "    print(f\"  âœ… Rolling Return\")\n",
    "else:\n",
    "    print(f\"  âŒ Rolling Return (desabilitado)\")\n",
    "if USE_MA_DISTANCE:\n",
    "    print(f\"  âœ… MA Distance\")\n",
    "else:\n",
    "    print(f\"  âŒ MA Distance (desabilitado)\")\n",
    "if USE_TREND_INDICATOR:\n",
    "    print(f\"  âœ… Trend Indicator\")\n",
    "else:\n",
    "    print(f\"  âŒ Trend Indicator (desabilitado)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar resultado do pipeline\n",
    "print(\"=== Dados ApÃ³s Pipeline ===\")\n",
    "#pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.max_rows', 10)\n",
    "df_analysis.tail(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 7: ClassificaÃ§Ã£o Manual de Regimes\n",
    "\n",
    "Uma abordagem Ã© usar thresholds manuais para classificar regimes baseado em slope e volatilidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analysis.regime_classifier import ManualRegimeClassifier, SlopeOnlyClassifier\n",
    "\n",
    "# Nomes das colunas\n",
    "slope_col = f'slope_{config.analysis.window_slope}'\n",
    "\n",
    "# Verificar se volatilidade estÃ¡ ativa\n",
    "if USE_VOLATILITY:\n",
    "    vol_col = f'volatility_{config.analysis.window_volatility}'\n",
    "    \n",
    "    # Criar classificador manual (thresholds automÃ¡ticos)\n",
    "    # Classifica em 6 regimes: bull/bear/flat Ã— high/low volatility\n",
    "    manual_classifier = ManualRegimeClassifier(\n",
    "        slope_column=slope_col,\n",
    "        volatility_column=vol_col\n",
    "    )\n",
    "    \n",
    "    # Classificar\n",
    "    df_manual = manual_classifier.classify(df_analysis)\n",
    "    \n",
    "    # Resultados\n",
    "    print(\"=== ClassificaÃ§Ã£o Manual de Regimes (com Volatilidade) ===\")\n",
    "    print(f\"\\nThresholds usados: {manual_classifier.get_thresholds()}\")\n",
    "    print(f\"\\nDistribuiÃ§Ã£o de regimes:\")\n",
    "    print(df_manual['regime'].value_counts())\n",
    "else:\n",
    "    # Sem volatilidade: classificar apenas como bull/bear/flat baseado no slope\n",
    "    slope_classifier = SlopeOnlyClassifier(slope_column=slope_col)\n",
    "    \n",
    "    # Classificar\n",
    "    df_manual = slope_classifier.classify(df_analysis)\n",
    "    \n",
    "    # Resultados\n",
    "    print(\"=== ClassificaÃ§Ã£o por Slope (bull/bear/flat) ===\")\n",
    "    print(f\"\\nThreshold usado: {slope_classifier.get_thresholds()}\")\n",
    "    print(f\"\\nDistribuiÃ§Ã£o de regimes:\")\n",
    "    print(df_manual['regime'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar distribuiÃ§Ã£o por regime\n",
    "regime_counts = df_manual['regime'].value_counts()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Cores para ambos os casos: 6 regimes (com volatilidade) ou 3 regimes (slope only)\n",
    "colors = {\n",
    "    # 6 regimes (ManualRegimeClassifier)\n",
    "    'bull_high_vol': 'lightgreen',\n",
    "    'bull_low_vol': 'darkgreen',\n",
    "    'bear_high_vol': 'lightcoral',\n",
    "    'bear_low_vol': 'darkred',\n",
    "    'flat_high_vol': 'yellow',\n",
    "    'flat_low_vol': 'gold',\n",
    "    # 3 regimes (SlopeOnlyClassifier)\n",
    "    'bull': 'green',\n",
    "    'bear': 'red',\n",
    "    'flat': 'gold'\n",
    "}\n",
    "bar_colors = [colors.get(r, 'gray') for r in regime_counts.index]\n",
    "regime_counts.plot(kind='bar', ax=ax, color=bar_colors, edgecolor='black')\n",
    "\n",
    "title = 'DistribuiÃ§Ã£o de Regimes (com Volatilidade)' if USE_VOLATILITY else 'DistribuiÃ§Ã£o de Regimes (Slope Only)'\n",
    "ax.set_title(title)\n",
    "ax.set_xlabel('Regime')\n",
    "ax.set_ylabel('FrequÃªncia')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 8: ClassificaÃ§Ã£o com K-Means\n",
    "\n",
    "K-Means detecta regimes automaticamente baseado em mÃºltiplas features.\n",
    "\n",
    "Isso Ã© mais robusto que thresholds manuais pois considera todas as features simultaneamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analysis.kmeans_regimes import KMeansRegimeClassifier\n",
    "\n",
    "# =============================================================================\n",
    "# Helper function: Obter colunas de features ativas baseadas na configuraÃ§Ã£o\n",
    "# =============================================================================\n",
    "def get_active_feature_columns():\n",
    "    \"\"\"\n",
    "    Retorna lista de colunas de features baseada nos indicadores ativos.\n",
    "    Esta funÃ§Ã£o Ã© usada pelo K-Means e pelos Explainers.\n",
    "    \"\"\"\n",
    "    features = [f'slope_{config.analysis.window_slope}']  # Slope Ã© sempre incluÃ­do\n",
    "    \n",
    "    if USE_VOLATILITY:\n",
    "        features.append(f'volatility_{config.analysis.window_volatility}')\n",
    "    \n",
    "    if USE_ROLLING_RETURN:\n",
    "        features.append(f'log_return_rolling_{config.analysis.window_rolling_return}')\n",
    "    \n",
    "    if USE_MA_DISTANCE:\n",
    "        features.append(f'ma_dist_{config.analysis.ma_fast_period}_{config.analysis.ma_slow_period}')\n",
    "    \n",
    "    if USE_TREND_INDICATOR:\n",
    "        # Usar trend_strength (abs) para evitar redundÃ¢ncia com slope\n",
    "        features.append(f'trend_strength_norm_{config.analysis.window_trend_indicator}')\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Obter features ativas\n",
    "active_features = get_active_feature_columns()\n",
    "print(f\"=== Features Ativas para Clustering ===\")\n",
    "for f in active_features:\n",
    "    print(f\"  - {f}\")\n",
    "\n",
    "# Criar classificador K-Means com features explÃ­citas\n",
    "kmeans = KMeansRegimeClassifier(\n",
    "    n_clusters=config.analysis.n_clusters,\n",
    "    feature_columns=active_features,  # Usar features ativas explicitamente\n",
    "    logger=logger\n",
    ")\n",
    "\n",
    "# Fit e Predict\n",
    "df_kmeans = kmeans.fit_predict(df_analysis)\n",
    "\n",
    "print(f\"\\n=== ClassificaÃ§Ã£o K-Means ===\")\n",
    "print(f\"Features usadas: {kmeans.feature_columns}\")\n",
    "print(f\"NÃºmero de clusters: {config.analysis.n_clusters}\")\n",
    "print(f\"\\nDistribuiÃ§Ã£o de clusters:\")\n",
    "print(df_kmeans['cluster'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EstatÃ­sticas por cluster\n",
    "future_col = f'log_return_future_{config.analysis.future_return_periods}'\n",
    "stats = kmeans.compute_statistics(df_kmeans, future_col)\n",
    "interpretations = kmeans.interpret_clusters(df_kmeans, slope_col)\n",
    "\n",
    "print(\"=== EstatÃ­sticas por Cluster ===\")\n",
    "for stat in stats:\n",
    "    interp = interpretations.get(stat.cluster_id, 'unknown')\n",
    "    print(f\"\\nCluster {stat.cluster_id} ({interp.upper()}):\")\n",
    "    print(f\"  ObservaÃ§Ãµes: {stat.count} ({stat.percentage:.1f}%)\")\n",
    "    print(f\"  Retorno futuro mÃ©dio: {stat.future_return_mean:.4f}\")\n",
    "    print(f\"  Desvio padrÃ£o: {stat.future_return_std:.4f}\")\n",
    "    print(f\"  Features mÃ©dias: {stat.feature_means}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 8b: Explicando os Clusters\n",
    "\n",
    "Usamos Decision Tree e Random Forest para entender quais variÃ¡veis sÃ£o mais importantes para definir cada cluster.\n",
    "\n",
    "Isso ajuda a interpretar o que o K-Means \"aprendeu\" sobre os regimes de mercado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analysis import CompositeExplainer, DecisionTreeExplainer\n",
    "\n",
    "# Criar explainer composto (Decision Tree + Random Forest)\n",
    "explainer = CompositeExplainer(\n",
    "    tree_max_depth=5,           # Profundidade da Ã¡rvore (interpretabilidade)\n",
    "    forest_n_estimators=100,    # NÃºmero de Ã¡rvores no Random Forest\n",
    "    min_samples_leaf=20         # MÃ­nimo de amostras por folha\n",
    ")\n",
    "\n",
    "# Usar as mesmas features ativas do K-Means (definidas em get_active_feature_columns)\n",
    "feature_cols = active_features  # Usa a variÃ¡vel definida na cÃ©lula do K-Means\n",
    "print(f\"Features usadas pelo Explainer: {feature_cols}\")\n",
    "\n",
    "# Fit no DataFrame com clusters\n",
    "explainer.fit(df_kmeans, cluster_column='cluster', feature_columns=feature_cols)\n",
    "\n",
    "# SumÃ¡rio completo\n",
    "explainer.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar importÃ¢ncias: Decision Tree vs Random Forest\n",
    "fig = explainer.plot_importances()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar a Ã¡rvore de decisÃ£o\n",
    "fig = explainer.plot_tree(figsize=(20, 10), fontsize=9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 3 features mais importantes\n",
    "print(\"=== Top 3 Features ===\")\n",
    "for feature, importance in explainer.get_top_features(3):\n",
    "    print(f\"  {feature}: {importance:.3f}\")\n",
    "\n",
    "# MÃ©tricas do modelo\n",
    "metrics = explainer.get_metrics()\n",
    "print(f\"\\n=== MÃ©tricas ===\")\n",
    "print(f\"  Accuracy (train): {metrics.accuracy:.1%}\")\n",
    "print(f\"  Accuracy (CV):    {metrics.cv_accuracy_mean:.1%} (+/- {metrics.cv_accuracy_std:.1%})\")\n",
    "print(f\"  Samples:          {metrics.n_samples}\")\n",
    "print(f\"  Clusters:         {metrics.n_clusters}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 9: CÃ¡lculo de Probabilidades\n",
    "\n",
    "Agora calculamos a probabilidade de atingir o retorno alvo, condicionada por regime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analysis.probability_calculator import ProbabilityCalculator\n",
    "\n",
    "# Usando classificaÃ§Ã£o manual\n",
    "prob_calc_manual = ProbabilityCalculator(\n",
    "    future_return_column=future_col,\n",
    "    target_return=config.analysis.target_return,\n",
    "    regime_column='regime'\n",
    ")\n",
    "\n",
    "# Gerar relatÃ³rio completo\n",
    "report = prob_calc_manual.generate_report(df_manual)\n",
    "\n",
    "print(\"=== RelatÃ³rio de Probabilidades (Regimes Manuais) ===\")\n",
    "print(f\"\\nRetorno alvo: {report['target_return']:.1%}\")\n",
    "print(f\"Log-retorno alvo: {report['log_target']:.4f}\")\n",
    "print(f\"\\nProbabilidade incondicional: {report['raw_probability_pct']:.2f}%\")\n",
    "\n",
    "print(f\"\\nProbabilidades condicionais:\")\n",
    "for regime, data in report['conditional_probabilities'].items():\n",
    "    print(f\"  {regime}:\")\n",
    "    print(f\"    P(hit) = {data['probability_pct']:.2f}%\")\n",
    "    print(f\"    n = {data['count']}\")\n",
    "    print(f\"    retorno mÃ©dio = {data['mean_return']:.4f}\")\n",
    "\n",
    "print(f\"\\nMÃ©tricas de separaÃ§Ã£o:\")\n",
    "print(f\"  Delta P: {report['separation_metrics']['delta_p']:.4f}\")\n",
    "print(f\"  (diferenÃ§a entre maior e menor probabilidade)\")\n",
    "print(f\"  Information Ratio: {report['separation_metrics']['information_ratio']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando classificaÃ§Ã£o K-Means\n",
    "prob_calc_kmeans = ProbabilityCalculator(\n",
    "    future_return_column=future_col,\n",
    "    target_return=config.analysis.target_return,\n",
    "    regime_column='cluster'\n",
    ")\n",
    "\n",
    "report_kmeans = prob_calc_kmeans.generate_report(df_kmeans)\n",
    "\n",
    "print(\"=== RelatÃ³rio de Probabilidades (K-Means) ===\")\n",
    "print(f\"\\nRetorno alvo: {report_kmeans['target_return']:.1%}\")\n",
    "print(f\"\\nProbabilidade incondicional: {report_kmeans['raw_probability_pct']:.2f}%\")\n",
    "\n",
    "print(f\"\\nProbabilidades por cluster:\")\n",
    "for cluster_id, data in sorted(report_kmeans['conditional_probabilities'].items()):\n",
    "    interp = interpretations.get(int(float(cluster_id)), 'unknown')\n",
    "    print(f\"  Cluster {cluster_id} ({interp}): P(hit) = {data['probability_pct']:.2f}% (n={data['count']})\")\n",
    "\n",
    "print(f\"\\nDelta P: {report_kmeans['separation_metrics']['delta_p']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 10: VisualizaÃ§Ãµes\n",
    "\n",
    "Visualizamos a distribuiÃ§Ã£o de retornos por regime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.visualization.histogram_plotter import HistogramPlotter, PriceRegimePlotter\n",
    "\n",
    "# Histograma geral\n",
    "hist_plotter = HistogramPlotter(\n",
    "    return_column=future_col,\n",
    "    regime_column='regime'\n",
    ")\n",
    "\n",
    "fig = hist_plotter.plot(df_manual)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramas por regime\n",
    "fig = hist_plotter.plot_by_regime(df_manual, target_return=config.analysis.target_return)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PreÃ§o com background de regime\n",
    "df_manual_indexed = df_manual.set_index('date')\n",
    "\n",
    "price_plotter = PriceRegimePlotter(regime_column='regime')\n",
    "fig = price_plotter.plot(df_manual_indexed)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 11: Walk-Forward Validation\n",
    "\n",
    "Para evitar overfitting, usamos walk-forward validation.\n",
    "\n",
    "Isso simula como o modelo performaria em tempo real, sempre treinando no passado e testando no futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analysis.time_series_splitter import TimeSeriesSplitter\n",
    "\n",
    "# Criar splitter\n",
    "splitter = TimeSeriesSplitter(train_ratio=0.7)\n",
    "\n",
    "# Demonstrar walk-forward splits\n",
    "print(\"=== Walk-Forward Splits ===\")\n",
    "for split in splitter.walk_forward_split(df, n_folds=5, min_train_size=252):\n",
    "    train_start = split.train['date'].min().date()\n",
    "    train_end = split.train['date'].max().date()\n",
    "    test_start = split.test['date'].min().date()\n",
    "    test_end = split.test['date'].max().date()\n",
    "    \n",
    "    print(f\"\\nFold {split.fold}:\")\n",
    "    print(f\"  Train: {train_start} a {train_end} ({len(split.train)} obs)\")\n",
    "    print(f\"  Test:  {test_start} a {test_end} ({len(split.test)} obs)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 12: OtimizaÃ§Ã£o com Algoritmo GenÃ©tico (Otimizado)\n",
    "\n",
    "O GA busca os melhores parÃ¢metros automaticamente.\n",
    "\n",
    "**OtimizaÃ§Ãµes implementadas:**\n",
    "1. **ParalelizaÃ§Ã£o**: AvaliaÃ§Ã£o de fitness usa mÃºltiplos cores CPU\n",
    "2. **Cache**: Cromossomos idÃªnticos nÃ£o sÃ£o reavaliados\n",
    "3. **Numba**: CÃ¡lculo de slope ~10-50x mais rÃ¡pido (apÃ³s warm-up)\n",
    "4. **KMeans otimizado**: Algoritmo Lloyd para melhor performance\n",
    "\n",
    "**NOTA sobre Numba**: A primeira execuÃ§Ã£o serÃ¡ mais lenta devido Ã  compilaÃ§Ã£o JIT. ExecuÃ§Ãµes subsequentes serÃ£o significativamente mais rÃ¡pidas. O cache do Numba persiste entre sessÃµes.\n",
    "\n",
    "**NOTA**: Esta etapa Ã© computacionalmente intensiva. Reduzimos os parÃ¢metros para demonstraÃ§Ã£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.calculators.slope_calculator import SlopeCalculator\n",
    "import multiprocessing as mp\n",
    "\n",
    "# Verificar otimizaÃ§Ãµes disponÃ­veis\n",
    "print(\"=== VerificaÃ§Ã£o de OtimizaÃ§Ãµes ===\")\n",
    "print(f\"Numba disponÃ­vel para SlopeCalculator: {SlopeCalculator.is_numba_available()}\")\n",
    "print(f\"CPUs disponÃ­veis para paralelizaÃ§Ã£o: {mp.cpu_count()}\")\n",
    "\n",
    "# ga_config jÃ¡ definido na cÃ©lula de configuraÃ§Ã£o centralizada\n",
    "print(\"\\n=== ConfiguraÃ§Ã£o do GA (da cÃ©lula centralizada) ===\")\n",
    "print(f\"Target Return: {ga_config.target_return:.1%}\")\n",
    "print(f\"Horizonte: {ga_config.horizon} dias\")\n",
    "print(f\"PopulaÃ§Ã£o: {ga_config.population_size}\")\n",
    "print(f\"GeraÃ§Ãµes: {ga_config.generations}\")\n",
    "print(f\"Folds: {ga_config.n_folds}\")\n",
    "print(f\"Early Stopping: {ga_config.early_stopping}\")\n",
    "\n",
    "# Estimativa de tempo\n",
    "tempo_por_gen = ga_config.population_size * 0.035  # ~0.035s por cromossomo\n",
    "tempo_total = ga_config.generations * tempo_por_gen\n",
    "print(f\"\\nTempo estimado: {tempo_total/60:.1f} minutos\")\n",
    "print(\"\\nNOTA: Use Ctrl+C para interromper e salvar checkpoint a qualquer momento.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from src.optimization.genetic_algorithm import GeneticAlgorithm, GACheckpoint\nfrom src.optimization.progress_callback import LiveProgressCallback\n\n# Criar callback de progresso visual\nprogress_callback = LiveProgressCallback(\n    total_generations=ga_config.generations,\n    population_size=ga_config.population_size,\n    update_every=1\n)\n\n# Executar GA\n# NOTA: parallel=False Ã© mais estÃ¡vel em Jupyter notebooks\nga = GeneticAlgorithm(\n    df, \n    ga_config, \n    logger=logger,\n    progress_callback=progress_callback,\n    n_workers=None\n)\n\ntry:\n    result = ga.run(\n        verbose=False,\n        parallel=False,  # Desativado para evitar problemas no Jupyter\n        auto_checkpoint_path=\"ga_checkpoint.json\",\n        checkpoint_every=10\n    )\nexcept KeyboardInterrupt:\n    print(\"\\nInterrompido! Salvando checkpoint...\")\n    ga.save_checkpoint(\"ga_checkpoint.json\")\n    print(\"Checkpoint salvo em 'ga_checkpoint.json'\")\n    print(\"Para retomar: checkpoint = GACheckpoint.load('ga_checkpoint.json')\")\n    raise\n\nprogress_callback.finalize()\n\nprint(\"\\n=== Melhores ParÃ¢metros Encontrados ===\")\nbest = result.best_chromosome\n\n# ParÃ¢metros sempre ativos\nprint(f\"  Window Slope: {best.window_slope}\")\nprint(f\"  N Clusters: {best.n_clusters}\")\n\n# ParÃ¢metros condicionais (sÃ³ mostrar se indicador estÃ¡ ativo)\nif best.use_volatility:\n    print(f\"  Window Volatility: {best.window_volatility}\")\nif best.use_rolling_return:\n    print(f\"  Window Rolling Return: {best.window_rolling_return}\")\nif best.use_ma_distance:\n    print(f\"  MA Fast Period: {best.ma_fast_period}\")\n    print(f\"  MA Slow Period: {best.ma_slow_period}\")\nif best.use_trend_indicator:\n    print(f\"  Window Trend Indicator: {best.window_trend_indicator}\")\n    print(f\"  Trend Slope Multiplier: {best.trend_slope_multiplier}\")\n\n# Mostrar quais indicadores estÃ£o ativos\nprint(f\"\\nIndicadores ativos:\")\nprint(f\"  {'âœ…' if best.use_volatility else 'âŒ'} Volatility\")\nprint(f\"  {'âœ…' if best.use_rolling_return else 'âŒ'} Rolling Return\")\nprint(f\"  {'âœ…' if best.use_ma_distance else 'âŒ'} MA Distance\")\nprint(f\"  {'âœ…' if best.use_trend_indicator else 'âŒ'} Trend Indicator\")\n\nprint(f\"\\nParÃ¢metros fixos (da configuraÃ§Ã£o):\")\nprint(f\"  Target Return: {ga_config.target_return:.2%}\")\nprint(f\"  Horizon: {ga_config.horizon} dias\")\n\nprint(f\"\\nMÃ©tricas:\")\nprint(f\"  Fitness: {result.best_fitness:.4f}\")\nprint(f\"  Delta P (test): {result.best_metrics.delta_p_test:.4f}\")\nprint(f\"  Overfitting Ratio: {result.best_metrics.overfitting_ratio:.2f}\")\n\nprint(f\"\\nEstatÃ­sticas:\")\nprint(f\"  Total avaliaÃ§Ãµes: {result.all_evaluations}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar evoluÃ§Ã£o do fitness\n",
    "generations = [h[0] for h in result.history]\n",
    "best_fitness = [h[1] for h in result.history]\n",
    "mean_fitness = [h[2] for h in result.history]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(generations, best_fitness, 'b-', label='Best Fitness', linewidth=2)\n",
    "ax.plot(generations, mean_fitness, 'g--', label='Mean Fitness', alpha=0.7)\n",
    "ax.set_xlabel('Generation')\n",
    "ax.set_ylabel('Fitness')\n",
    "ax.set_title('EvoluÃ§Ã£o do Algoritmo GenÃ©tico')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 13: Aplicar Melhores ParÃ¢metros\n",
    "\n",
    "Agora aplicamos os parÃ¢metros otimizados e recalculamos as probabilidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.optimization.calculator_factory import CalculatorFactory\n",
    "\n",
    "# Factory para criar pipeline com os melhores parÃ¢metros\n",
    "# horizon vem da configuraÃ§Ã£o, nÃ£o do cromossomo\n",
    "factory = CalculatorFactory(horizon=ga_config.horizon)\n",
    "best_pipeline = factory.create_pipeline(best)\n",
    "feature_cols = factory.get_feature_columns(best)\n",
    "future_col_best = factory.get_future_return_column()\n",
    "\n",
    "# Processar dados\n",
    "df_best = best_pipeline.run(df)\n",
    "\n",
    "# Clustering\n",
    "best_kmeans = KMeansRegimeClassifier(\n",
    "    n_clusters=best.n_clusters,\n",
    "    feature_columns=feature_cols\n",
    ")\n",
    "df_best = best_kmeans.fit_predict(df_best)\n",
    "\n",
    "# Probabilidades (target_return vem da configuraÃ§Ã£o)\n",
    "best_prob = ProbabilityCalculator(\n",
    "    future_return_column=future_col_best,\n",
    "    target_return=ga_config.target_return,\n",
    "    regime_column='cluster'\n",
    ")\n",
    "\n",
    "best_report = best_prob.generate_report(df_best)\n",
    "\n",
    "print(\"=== RelatÃ³rio com ParÃ¢metros Otimizados ===\")\n",
    "print(f\"\\nRetorno alvo: {ga_config.target_return:.1%}\")\n",
    "print(f\"Horizonte: {ga_config.horizon} dias\")\n",
    "print(f\"\\nProbabilidade incondicional: {best_report['raw_probability_pct']:.2f}%\")\n",
    "\n",
    "# Interpretar clusters\n",
    "slope_col_best = f'slope_{best.window_slope}'\n",
    "best_interp = best_kmeans.interpret_clusters(df_best, slope_col_best)\n",
    "\n",
    "print(f\"\\nProbabilidades por cluster:\")\n",
    "for cluster_id, data in sorted(best_report['conditional_probabilities'].items()):\n",
    "    interp = best_interp.get(int(float(cluster_id)), 'unknown')\n",
    "    print(f\"  Cluster {cluster_id} ({interp.upper()}): P(hit) = {data['probability_pct']:.2f}% (n={data['count']})\")\n",
    "\n",
    "print(f\"\\nDelta P: {best_report['separation_metrics']['delta_p']:.4f}\")\n",
    "print(f\"Information Ratio: {best_report['separation_metrics']['information_ratio']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicar clusters dos parÃ¢metros otimizados\n",
    "from src.analysis import CompositeExplainer\n",
    "\n",
    "best_explainer = CompositeExplainer(\n",
    "    tree_max_depth=5,\n",
    "    forest_n_estimators=100,\n",
    "    min_samples_leaf=20\n",
    ")\n",
    "\n",
    "# Fit no DataFrame com clusters otimizados\n",
    "best_explainer.fit(df_best, cluster_column='cluster', feature_columns=feature_cols)\n",
    "\n",
    "# SumÃ¡rio\n",
    "print(\"=== ExplicaÃ§Ã£o dos Clusters (ParÃ¢metros Otimizados) ===\")\n",
    "best_explainer.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar importÃ¢ncias e Ã¡rvore (parÃ¢metros otimizados)\n",
    "fig = best_explainer.plot_importances()\n",
    "plt.suptitle('Feature Importances - ParÃ¢metros Otimizados', y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# Visualizar Ã¡rvore de decisÃ£o\n",
    "fig = best_explainer.plot_tree(figsize=(18, 8), fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 14: VisualizaÃ§Ãµes com ParÃ¢metros Otimizados\n",
    "\n",
    "Agora repetimos todas as visualizaÃ§Ãµes usando os parÃ¢metros do indivÃ­duo vencedor do GA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EstatÃ­sticas por cluster com parÃ¢metros otimizados\n",
    "stats_best = best_kmeans.compute_statistics(df_best, future_col_best)\n",
    "\n",
    "print(\"=== EstatÃ­sticas por Cluster (ParÃ¢metros Otimizados) ===\")\n",
    "for stat in stats_best:\n",
    "    interp = best_interp.get(stat.cluster_id, 'unknown')\n",
    "    print(f\"\\nCluster {stat.cluster_id} ({interp.upper()}):\")\n",
    "    print(f\"  ObservaÃ§Ãµes: {stat.count} ({stat.percentage:.1f}%)\")\n",
    "    print(f\"  Retorno futuro mÃ©dio: {stat.future_return_mean:.4f}\")\n",
    "    print(f\"  Desvio padrÃ£o: {stat.future_return_std:.4f}\")\n",
    "    print(f\"  Features mÃ©dias: {stat.feature_means}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograma de retornos com parÃ¢metros otimizados\n",
    "hist_plotter_best = HistogramPlotter(\n",
    "    return_column=future_col_best,\n",
    "    regime_column='cluster'\n",
    ")\n",
    "\n",
    "fig = hist_plotter_best.plot(df_best)\n",
    "plt.suptitle(f'DistribuiÃ§Ã£o de Retornos Futuros ({ga_config.horizon} dias) - ParÃ¢metros Otimizados', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramas por cluster com linha do target\n",
    "fig = hist_plotter_best.plot_by_regime(df_best, target_return=ga_config.target_return)\n",
    "plt.suptitle(f'DistribuiÃ§Ã£o por Cluster - Target: {ga_config.target_return:.1%} em {ga_config.horizon} dias', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PreÃ§o com background de cluster otimizado\n",
    "df_best_indexed = df_best.set_index('date')\n",
    "\n",
    "price_plotter_best = PriceRegimePlotter(regime_column='cluster')\n",
    "fig = price_plotter_best.plot(df_best_indexed, cluster_interpretations=best_interp)\n",
    "plt.suptitle('PreÃ§o com Regimes Otimizados pelo GA', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GrÃ¡fico de barras: Probabilidade por Cluster\n",
    "clusters = []\n",
    "probs = []\n",
    "colors = []\n",
    "color_map = {'bull': 'green', 'bear': 'red', 'flat': 'gold'}\n",
    "\n",
    "for cluster_id, data in sorted(best_report['conditional_probabilities'].items()):\n",
    "    interp = best_interp.get(int(float(cluster_id)), 'flat')\n",
    "    clusters.append(f\"Cluster {int(float(cluster_id))}\\n({interp})\")\n",
    "    probs.append(data['probability_pct'])\n",
    "    colors.append(color_map.get(interp, 'gray'))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "bars = ax.bar(clusters, probs, color=colors, edgecolor='black', alpha=0.8)\n",
    "\n",
    "# Linha horizontal para probabilidade incondicional\n",
    "ax.axhline(y=best_report['raw_probability_pct'], color='blue', linestyle='--', \n",
    "           linewidth=2, label=f\"P incondicional: {best_report['raw_probability_pct']:.1f}%\")\n",
    "\n",
    "# Adicionar valores nas barras\n",
    "for bar, prob in zip(bars, probs):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
    "            f'{prob:.1f}%', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "ax.set_ylabel('Probabilidade (%)')\n",
    "ax.set_title(f'Probabilidade de Atingir {ga_config.target_return:.1%} em {ga_config.horizon} dias por Cluster')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nDelta P (separaÃ§Ã£o): {best_report['separation_metrics']['delta_p']:.4f}\")\n",
    "print(f\"Melhor cluster: {max(best_report['conditional_probabilities'].items(), key=lambda x: x[1]['probability_pct'])[0]}\")\n",
    "print(f\"Pior cluster: {min(best_report['conditional_probabilities'].items(), key=lambda x: x[1]['probability_pct'])[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar regime atual e probabilidade\n",
    "last_row = df_best.iloc[-1]\n",
    "current_cluster = int(last_row['cluster'])\n",
    "current_interp = best_interp.get(current_cluster, 'unknown')\n",
    "current_prob = best_report['conditional_probabilities'][str(float(current_cluster))]['probability_pct']\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SITUAÃ‡ÃƒO ATUAL\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nData mais recente: {last_row['date'].strftime('%Y-%m-%d')}\")\n",
    "print(f\"PreÃ§o de fechamento: R$ {last_row['close']:.2f}\")\n",
    "print(f\"\\nRegime atual: Cluster {current_cluster} ({current_interp.upper()})\")\n",
    "\n",
    "# Mostrar indicadores atuais\n",
    "print(f\"\\n=== Indicadores Atuais ===\")\n",
    "print(f\"  Slope ({best.window_slope}d): {last_row[f'slope_{best.window_slope}']:.6f}\")\n",
    "if best.use_volatility:\n",
    "    print(f\"  Volatility ({best.window_volatility}d): {last_row[f'volatility_{best.window_volatility}']:.4f}\")\n",
    "if best.use_rolling_return:\n",
    "    print(f\"  Log Return Rolling ({best.window_rolling_return}d): {last_row[f'log_return_rolling_{best.window_rolling_return}']:.4f}\")\n",
    "if best.use_ma_distance:\n",
    "    print(f\"  MA Distance ({best.ma_fast_period}/{best.ma_slow_period}): {last_row[f'ma_dist_{best.ma_fast_period}_{best.ma_slow_period}']:.4f}\")\n",
    "if best.use_trend_indicator:\n",
    "    trend_col = f'trend_indicator_norm_{best.window_trend_indicator}'\n",
    "    trend_value = last_row[trend_col]\n",
    "    trend_interpretation = \"BULLISH\" if trend_value > 0.3 else \"BEARISH\" if trend_value < -0.3 else \"NEUTRAL\"\n",
    "    print(f\"  Trend Indicator ({best.window_trend_indicator}d, mult={best.trend_slope_multiplier}): {trend_value:.4f} ({trend_interpretation})\")\n",
    "\n",
    "print(f\"\\nProbabilidade de atingir {ga_config.target_return:.1%} em {ga_config.horizon} dias:\")\n",
    "print(f\"  -> {current_prob:.1f}%\")\n",
    "print(f\"\\nProbabilidade incondicional (mÃ©dia histÃ³rica): {best_report['raw_probability_pct']:.1f}%\")\n",
    "\n",
    "# ComparaÃ§Ã£o\n",
    "diff = current_prob - best_report['raw_probability_pct']\n",
    "if diff > 0:\n",
    "    print(f\"\\nâœ… Regime atual tem probabilidade {diff:.1f} pontos percentuais ACIMA da mÃ©dia\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸ Regime atual tem probabilidade {abs(diff):.1f} pontos percentuais ABAIXO da mÃ©dia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<cell_type>markdown</cell_type>## Etapa 15: AnÃ¡lise Dual - Fechar vs Tocar\n",
    "\n",
    "Comparamos duas probabilidades diferentes:\n",
    "- **P(fechar)**: Probabilidade do preÃ§o FECHAR acima do alvo em t+H\n",
    "- **P(tocar)**: Probabilidade do preÃ§o TOCAR o alvo em algum momento entre t+1 e t+H\n",
    "\n",
    "Esta anÃ¡lise Ã© Ãºtil para operaÃ§Ãµes de opÃ§Ãµes e stop-loss/take-profit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.calculators import FutureTouchCalculatorVectorized\n",
    "from src.analysis import DualProbabilityCalculator\n",
    "\n",
    "# Adicionar colunas de touch ao DataFrame com parÃ¢metros otimizados\n",
    "touch_calc = FutureTouchCalculatorVectorized(horizon=ga_config.horizon)\n",
    "df_dual = touch_calc.calculate(df_best)\n",
    "\n",
    "print(\"=== Novas Colunas de Touch ===\")\n",
    "print(f\"Colunas adicionadas: {touch_calc.output_columns}\")\n",
    "print(f\"\\nExemplo dos dados:\")\n",
    "print(df_dual[['date', 'close', f'log_return_future_{ga_config.horizon}', \n",
    "               f'log_return_touch_max_{ga_config.horizon}']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar calculador dual\n",
    "dual_calc = DualProbabilityCalculator(\n",
    "    close_return_column=f'log_return_future_{ga_config.horizon}',\n",
    "    touch_return_column=f'log_return_touch_max_{ga_config.horizon}',  # Para alvos de alta\n",
    "    target_return=ga_config.target_return,\n",
    "    regime_column='cluster',\n",
    "    horizon=ga_config.horizon\n",
    ")\n",
    "\n",
    "# Imprimir comparaÃ§Ã£o formatada\n",
    "dual_calc.print_comparison(df_dual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GrÃ¡fico comparativo: P(fechar) vs P(tocar) por cluster\n",
    "dual_report = dual_calc.generate_report(df_dual)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "clusters_list = sorted(dual_report['conditional_probabilities'].keys())\n",
    "x = np.arange(len(clusters_list))\n",
    "width = 0.35\n",
    "\n",
    "close_probs = [dual_report['conditional_probabilities'][c]['prob_close'] * 100 for c in clusters_list]\n",
    "touch_probs = [dual_report['conditional_probabilities'][c]['prob_touch'] * 100 for c in clusters_list]\n",
    "\n",
    "bars1 = ax.bar(x - width/2, close_probs, width, label='P(fechar)', color='steelblue', alpha=0.8)\n",
    "bars2 = ax.bar(x + width/2, touch_probs, width, label='P(tocar)', color='coral', alpha=0.8)\n",
    "\n",
    "# Labels nos clusters\n",
    "cluster_labels = []\n",
    "for c in clusters_list:\n",
    "    interp = best_interp.get(int(float(c)), 'unknown')\n",
    "    cluster_labels.append(f\"Cluster {int(float(c))}\\n({interp})\")\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(cluster_labels)\n",
    "ax.set_ylabel('Probabilidade (%)')\n",
    "ax.set_title(f'ComparaÃ§Ã£o: P(fechar) vs P(tocar) - Target: {ga_config.target_return:.1%} em {ga_config.horizon} dias')\n",
    "ax.legend()\n",
    "\n",
    "# Adicionar valores nas barras\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height, f'{height:.1f}%',\n",
    "            ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height, f'{height:.1f}%',\n",
    "            ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Ratio touch/close\n",
    "print(\"\\n=== Ratio Touch/Close por Cluster ===\")\n",
    "for c in clusters_list:\n",
    "    data = dual_report['conditional_probabilities'][c]\n",
    "    ratio = data['touch_vs_close_ratio']\n",
    "    interp = best_interp.get(int(float(c)), 'unknown')\n",
    "    print(f\"Cluster {int(float(c))} ({interp}): {ratio:.2f}x mais provÃ¡vel tocar que fechar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SituaÃ§Ã£o atual com anÃ¡lise dual\n",
    "last_row = df_dual.iloc[-1]\n",
    "current_cluster = int(last_row['cluster'])\n",
    "current_interp = best_interp.get(current_cluster, 'unknown')\n",
    "\n",
    "current_data = dual_report['conditional_probabilities'][str(float(current_cluster))]\n",
    "current_prob_close = current_data['prob_close'] * 100\n",
    "current_prob_touch = current_data['prob_touch'] * 100\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SITUAÃ‡ÃƒO ATUAL - ANÃLISE DUAL\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nData: {last_row['date'].strftime('%Y-%m-%d')}\")\n",
    "print(f\"PreÃ§o: R$ {last_row['close']:.2f}\")\n",
    "print(f\"Regime: Cluster {current_cluster} ({current_interp.upper()})\")\n",
    "\n",
    "# Mostrar indicadores atuais incluindo trend\n",
    "print(f\"\\n=== Indicadores Atuais ===\")\n",
    "print(f\"  Slope ({best.window_slope}d): {last_row[f'slope_{best.window_slope}']:.6f}\")\n",
    "if best.use_trend_indicator:\n",
    "    trend_col = f'trend_indicator_norm_{best.window_trend_indicator}'\n",
    "    trend_value = last_row[trend_col]\n",
    "    trend_interpretation = \"BULLISH\" if trend_value > 0.3 else \"BEARISH\" if trend_value < -0.3 else \"NEUTRAL\"\n",
    "    print(f\"  Trend Indicator ({best.window_trend_indicator}d, mult={best.trend_slope_multiplier}): {trend_value:.4f} ({trend_interpretation})\")\n",
    "\n",
    "print(f\"\\nProbabilidade de atingir {ga_config.target_return:.1%} em {ga_config.horizon} dias:\")\n",
    "print(f\"  P(fechar â‰¥ alvo): {current_prob_close:.1f}%\")\n",
    "print(f\"  P(tocar o alvo):  {current_prob_touch:.1f}%\")\n",
    "print(f\"  Ratio:            {current_prob_touch/current_prob_close:.2f}x\")\n",
    "\n",
    "print(f\"\\nðŸ“ˆ InterpretaÃ§Ã£o:\")\n",
    "print(f\"  Ã‰ {current_prob_touch/current_prob_close:.1f}x mais provÃ¡vel o preÃ§o TOCAR o alvo\")\n",
    "print(f\"  do que FECHAR acima dele.\")\n",
    "print(f\"\\n  Isso Ã© Ãºtil para:\")\n",
    "print(f\"  - OpÃ§Ãµes: P(tocar) relevante para barreiras knock-in/knock-out\")\n",
    "print(f\"  - Trading: P(tocar) para stop-loss e take-profit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 16: Salvando o Modelo para ProduÃ§Ã£o\n",
    "\n",
    "Usamos `RegimePredictor` para encapsular o modelo treinado e facilitar previsÃµes futuras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.prediction import RegimePredictor\n",
    "\n",
    "# Criar predictor a partir dos resultados do GA\n",
    "predictor = RegimePredictor(\n",
    "    chromosome=best,                      # Cromossomo otimizado\n",
    "    target_return=ga_config.target_return,\n",
    "    horizon=ga_config.horizon,\n",
    "    ticker=ticker,\n",
    "    data_dir=\"../data\"\n",
    ")\n",
    "\n",
    "# Treinar com os dados histÃ³ricos\n",
    "predictor.fit(df)\n",
    "\n",
    "# Salvar modelo para uso futuro\n",
    "predictor.save(\"../models/bova11_predictor\")\n",
    "print(\"âœ… Modelo salvo em ../models/bova11_predictor.joblib e .json\")\n",
    "\n",
    "# Carregar modelo (simulando uso em produÃ§Ã£o)\n",
    "predictor_loaded = RegimePredictor.load(\"../models/bova11_predictor\", data_dir=\"../data\")\n",
    "print(\"âœ… Modelo carregado com sucesso!\")\n",
    "\n",
    "# Fazer previsÃ£o do regime atual\n",
    "result = predictor_loaded.predict_current()\n",
    "\n",
    "# Exibir status formatado\n",
    "predictor_loaded.print_status(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 17: OtimizaÃ§Ã£o Multi-Alvo\n",
    "\n",
    "Para diferentes targets de retorno, o GA pode encontrar parÃ¢metros diferentes.\n",
    "O `MultiTargetOptimizer` roda GAs independentes para cada alvo e cria uma matriz de probabilidades.\n",
    "\n",
    "**NOTA**: Esta etapa Ã© MUITO intensiva computacionalmente. Use com cautela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de uso do StrikeGridOptimizer com Progress Callback e Cluster Explainer\n",
    "\n",
    "from src.optimization import StrikeGridOptimizer\n",
    "from src.optimization.progress_callback import SimpleProgressCallback\n",
    "from src.prediction import StrikeGridPredictor\n",
    "from src.analysis import CompositeExplainer, DecisionTreeExplainer\n",
    "\n",
    "# PreÃ§o atual do ativo\n",
    "current_price = df['close'].iloc[-1]\n",
    "print(f\"PreÃ§o atual: R$ {current_price:.2f}\")\n",
    "\n",
    "# Definir strikes (exemplo para BOVA11)\n",
    "strikes = list(range(int(current_price * 0.95), int(current_price * 1.10), 1))  # -5% a +10%, step de R$ 1\n",
    "print(f\"\\nStrikes definidos: {strikes}\")\n",
    "print(f\"Total de GAs a executar: {len(strikes)}\")\n",
    "\n",
    "# Preview da conversÃ£o strike â†’ target\n",
    "print(\"\\n=== Preview Strike â†’ Target ===\")\n",
    "print(f\"{'Strike':<12} {'Retorno':<12} {'DireÃ§Ã£o':<10}\")\n",
    "print(\"-\" * 34)\n",
    "for strike in strikes[:5]:\n",
    "    target_return = (strike / current_price) - 1\n",
    "    direction = 'UP' if target_return > 0 else 'DOWN' if target_return < 0 else 'ATM'\n",
    "    print(f\"R$ {strike:<9.2f} {target_return*100:+.2f}%       {direction:<10}\")\n",
    "if len(strikes) > 5:\n",
    "    print(f\"... ({len(strikes) - 5} mais)\")\n",
    "\n",
    "# Usando multi_ga_config da cÃ©lula de configuraÃ§Ã£o centralizada\n",
    "print(f\"\\nUsando multi_ga_config da cÃ©lula centralizada:\")\n",
    "print(f\"  PopulaÃ§Ã£o: {multi_ga_config.population_size}\")\n",
    "print(f\"  GeraÃ§Ãµes: {multi_ga_config.generations}\")\n",
    "print(f\"  Early Stopping: {multi_ga_config.early_stopping}\")\n",
    "\n",
    "# Factory para criar callback de progresso para cada GA\n",
    "def create_ga_callback(strike_idx, strike):\n",
    "    return SimpleProgressCallback(\n",
    "        total_generations=multi_ga_config.generations,\n",
    "        print_every=5  # Atualiza a cada 5 geraÃ§Ãµes\n",
    "    )\n",
    "\n",
    "# Executar otimizaÃ§Ã£o\n",
    "strike_optimizer = StrikeGridOptimizer(\n",
    "    df=df,\n",
    "    current_price=current_price,\n",
    "    strikes=strikes,\n",
    "    horizon=HORIZON,\n",
    "    ga_config=multi_ga_config\n",
    ")\n",
    "\n",
    "print(f\"\\nâ³ Iniciando otimizaÃ§Ã£o para {len(strikes)} strikes...\")\n",
    "\n",
    "strike_results = strike_optimizer.run(\n",
    "    verbose=True,\n",
    "    ga_progress_callback_factory=create_ga_callback,\n",
    "    parallel_ga=False  # Melhor para Jupyter notebooks\n",
    ")\n",
    "\n",
    "# Salvar resultados\n",
    "strike_results.save(\"../models/strike_grid_h2\")\n",
    "\n",
    "# ============================================================================\n",
    "# EXPLICAÃ‡ÃƒO DOS CLUSTERS POR STRIKE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EXPLICAÃ‡ÃƒO DOS CLUSTERS POR STRIKE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Armazenar explicaÃ§Ãµes\n",
    "strike_explanations = {}\n",
    "\n",
    "for strike, result in strike_results.results.items():\n",
    "    print(f\"\\n--- Strike R$ {strike:.2f} ---\")\n",
    "    \n",
    "    # Criar pipeline e processar dados com os parÃ¢metros do strike\n",
    "    # result Ã© MultiTargetResult, acessar cromossomo via ga_result.best_chromosome\n",
    "    from src.optimization.calculator_factory import CalculatorFactory\n",
    "    \n",
    "    best_chromosome = result.ga_result.best_chromosome\n",
    "    \n",
    "    factory = CalculatorFactory(horizon=HORIZON)\n",
    "    strike_pipeline = factory.create_pipeline(best_chromosome)\n",
    "    feature_cols_strike = factory.get_feature_columns(best_chromosome)\n",
    "    \n",
    "    # Processar dados\n",
    "    df_strike = strike_pipeline.run(df)\n",
    "    \n",
    "    # Clustering\n",
    "    strike_kmeans = KMeansRegimeClassifier(\n",
    "        n_clusters=best_chromosome.n_clusters,\n",
    "        feature_columns=feature_cols_strike\n",
    "    )\n",
    "    df_strike = strike_kmeans.fit_predict(df_strike)\n",
    "    \n",
    "    # Explicar clusters\n",
    "    strike_explainer = DecisionTreeExplainer(max_depth=4, min_samples_leaf=20)\n",
    "    strike_explainer.fit(df_strike, cluster_column='cluster', feature_columns=feature_cols_strike)\n",
    "    \n",
    "    # MÃ©tricas\n",
    "    metrics = strike_explainer.get_metrics()\n",
    "    print(f\"  Accuracy: {metrics.cv_accuracy_mean:.1%} (+/- {metrics.cv_accuracy_std:.1%})\")\n",
    "    \n",
    "    # Top features\n",
    "    print(f\"  Top Features:\")\n",
    "    for feature, importance in strike_explainer.get_top_features(3):\n",
    "        print(f\"    - {feature}: {importance:.3f}\")\n",
    "    \n",
    "    # Guardar explicaÃ§Ã£o\n",
    "    strike_explanations[strike] = {\n",
    "        'explainer': strike_explainer,\n",
    "        'top_features': strike_explainer.get_top_features(3),\n",
    "        'accuracy': metrics.cv_accuracy_mean,\n",
    "        'rules': strike_explainer.get_rules()\n",
    "    }\n",
    "\n",
    "# Criar predictor\n",
    "strike_predictor = StrikeGridPredictor.from_optimization(strike_results, df)\n",
    "strike_predictor.save(\"../models/strike_grid_h2_predictor\")\n",
    "\n",
    "# Ver matriz de strikes\n",
    "strike_predictor.print_matrix(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumo das explicaÃ§Ãµes por strike - VisualizaÃ§Ã£o\n",
    "print(\"=\" * 70)\n",
    "print(\"RESUMO: FEATURES MAIS IMPORTANTES POR STRIKE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Criar DataFrame com resumo\n",
    "summary_data = []\n",
    "for strike, explanation in strike_explanations.items():\n",
    "    top_feat = explanation['top_features'][0] if explanation['top_features'] else ('N/A', 0)\n",
    "    summary_data.append({\n",
    "        'Strike': f\"R$ {strike:.0f}\",\n",
    "        'Target': f\"{((strike / current_price) - 1) * 100:+.1f}%\",\n",
    "        'Top Feature': top_feat[0],\n",
    "        'Importance': f\"{top_feat[1]:.3f}\",\n",
    "        'Accuracy': f\"{explanation['accuracy']:.1%}\"\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# GrÃ¡fico: Feature mais importante por strike\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "strike_values = list(strike_explanations.keys())\n",
    "top_features_by_strike = [exp['top_features'][0][0] if exp['top_features'] else 'N/A' \n",
    "                          for exp in strike_explanations.values()]\n",
    "importances = [exp['top_features'][0][1] if exp['top_features'] else 0 \n",
    "               for exp in strike_explanations.values()]\n",
    "\n",
    "# Cores por feature\n",
    "unique_features = list(set(top_features_by_strike))\n",
    "color_palette = plt.cm.tab10.colors\n",
    "feature_colors = {feat: color_palette[i % len(color_palette)] for i, feat in enumerate(unique_features)}\n",
    "bar_colors = [feature_colors[feat] for feat in top_features_by_strike]\n",
    "\n",
    "bars = ax.bar(range(len(strike_values)), importances, color=bar_colors, edgecolor='black', alpha=0.8)\n",
    "\n",
    "ax.set_xticks(range(len(strike_values)))\n",
    "ax.set_xticklabels([f\"R${s:.0f}\" for s in strike_values], rotation=45, ha='right')\n",
    "ax.set_xlabel('Strike')\n",
    "ax.set_ylabel('Importance')\n",
    "ax.set_title('Feature Mais Importante por Strike')\n",
    "\n",
    "# Legenda\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor=color, label=feat) for feat, color in feature_colors.items()]\n",
    "ax.legend(handles=legend_elements, loc='upper right', fontsize=8)\n",
    "\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 18: Grade de Strikes para OpÃ§Ãµes\n",
    "\n",
    "O `StrikeGridOptimizer` Ã© similar ao MultiTargetOptimizer, mas trabalha com preÃ§os absolutos (strikes).\n",
    "Ideal para precificaÃ§Ã£o de opÃ§Ãµes.\n",
    "\n",
    "**Fluxo:**\n",
    "1. Define strikes (ex: R$ 120, 125, 130...)\n",
    "2. Converte cada strike para target return: `(strike / preÃ§o_atual) - 1`\n",
    "3. Roda GA para cada target exato\n",
    "4. Gera matriz de probabilidades por strike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de uso do StrikeGridOptimizer com Progress Callback\n",
    "\n",
    "from src.optimization import StrikeGridOptimizer\n",
    "from src.optimization.progress_callback import SimpleProgressCallback\n",
    "from src.prediction import StrikeGridPredictor\n",
    "\n",
    "# PreÃ§o atual do ativo\n",
    "current_price = df['close'].iloc[-1]\n",
    "print(f\"PreÃ§o atual: R$ {current_price:.2f}\")\n",
    "\n",
    "# Definir strikes (exemplo para BOVA11)\n",
    "strikes = list(range(int(current_price * 0.95), int(current_price * 1.10), 1))  # -5% a +10%, step de R$ 1\n",
    "print(f\"\\nStrikes definidos: {strikes}\")\n",
    "print(f\"Total de GAs a executar: {len(strikes)}\")\n",
    "\n",
    "# Preview da conversÃ£o strike â†’ target\n",
    "print(\"\\n=== Preview Strike â†’ Target ===\")\n",
    "print(f\"{'Strike':<12} {'Retorno':<12} {'DireÃ§Ã£o':<10}\")\n",
    "print(\"-\" * 34)\n",
    "for strike in strikes[:5]:\n",
    "    target_return = (strike / current_price) - 1\n",
    "    direction = 'UP' if target_return > 0 else 'DOWN' if target_return < 0 else 'ATM'\n",
    "    print(f\"R$ {strike:<9.2f} {target_return*100:+.2f}%       {direction:<10}\")\n",
    "if len(strikes) > 5:\n",
    "    print(f\"... ({len(strikes) - 5} mais)\")\n",
    "\n",
    "# Usando multi_ga_config da cÃ©lula de configuraÃ§Ã£o centralizada\n",
    "print(f\"\\nUsando multi_ga_config da cÃ©lula centralizada:\")\n",
    "print(f\"  PopulaÃ§Ã£o: {multi_ga_config.population_size}\")\n",
    "print(f\"  GeraÃ§Ãµes: {multi_ga_config.generations}\")\n",
    "print(f\"  Early Stopping: {multi_ga_config.early_stopping}\")\n",
    "\n",
    "# Factory para criar callback de progresso para cada GA\n",
    "def create_ga_callback(strike_idx, strike):\n",
    "    return SimpleProgressCallback(\n",
    "        total_generations=multi_ga_config.generations,\n",
    "        print_every=5  # Atualiza a cada 5 geraÃ§Ãµes\n",
    "    )\n",
    "\n",
    "# Executar otimizaÃ§Ã£o\n",
    "strike_optimizer = StrikeGridOptimizer(\n",
    "    df=df,\n",
    "    current_price=current_price,\n",
    "    strikes=strikes,\n",
    "    horizon=HORIZON,\n",
    "    ga_config=multi_ga_config\n",
    ")\n",
    "\n",
    "print(f\"\\nâ³ Iniciando otimizaÃ§Ã£o para {len(strikes)} strikes...\")\n",
    "\n",
    "strike_results = strike_optimizer.run(\n",
    "    verbose=True,\n",
    "    ga_progress_callback_factory=create_ga_callback,\n",
    "    parallel_ga=False  # Melhor para Jupyter notebooks\n",
    ")\n",
    "\n",
    "# Salvar resultados\n",
    "strike_results.save(\"../models/strike_grid_h2\")\n",
    "\n",
    "# Criar predictor\n",
    "strike_predictor = StrikeGridPredictor.from_optimization(strike_results, df)\n",
    "strike_predictor.save(\"../models/strike_grid_h2_predictor\")\n",
    "\n",
    "# Ver matriz de strikes\n",
    "strike_predictor.print_matrix(ticker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConclusÃ£o\n",
    "\n",
    "Este notebook demonstrou o fluxo completo do sistema QuantNote:\n",
    "\n",
    "1. **ConfiguraÃ§Ã£o** com validaÃ§Ã£o via Pydantic\n",
    "2. **ObtenÃ§Ã£o de dados** do Yahoo Finance com rate limiting\n",
    "3. **ValidaÃ§Ã£o** de dados com mÃºltiplos validators\n",
    "4. **Pipeline de calculadores** com resoluÃ§Ã£o automÃ¡tica de dependÃªncias\n",
    "5. **ClassificaÃ§Ã£o de regimes** (manual e K-Means)\n",
    "6. **CÃ¡lculo de probabilidades** condicionais\n",
    "7. **VisualizaÃ§Ã£o** de distribuiÃ§Ãµes\n",
    "8. **Walk-forward validation** para evitar overfitting\n",
    "9. **OtimizaÃ§Ã£o** com algoritmo genÃ©tico\n",
    "10. **AnÃ¡lise dual** - P(fechar) vs P(tocar)\n",
    "\n",
    "### MÃ©tricas de Probabilidade\n",
    "\n",
    "- **P(fechar)**: Probabilidade de fechar acima do alvo no final do perÃ­odo\n",
    "- **P(tocar)**: Probabilidade de atingir o alvo em algum momento durante o perÃ­odo\n",
    "\n",
    "### PrÃ³ximos Passos\n",
    "\n",
    "- Testar com outros ativos\n",
    "- Ajustar parÃ¢metros do GA para busca mais ampla\n",
    "- Implementar novos indicadores (RSI, MACD, etc.)\n",
    "- Integrar com sistema de backtesting\n",
    "- Usar P(tocar) para otimizaÃ§Ã£o de opÃ§Ãµes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}